{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/NLP_project/blob/STS%2Foptimizer/STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n",
        "\n"
      ],
      "metadata": {
        "id": "3qfGz4Pa-Whu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "6R8hyvUu-1sK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sw7ilyV-KU8",
        "outputId": "e2f7e5c9-e1cf-45dd-c8ec-74ac858104bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,  RandomSampler, SequentialSampler, random_split\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "kpKhz3Xi_A2j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZepTYxNV_QPi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJA6wul9_SI3",
        "outputId": "f524fdc0-6475-43c1-cba1-eaae10022042"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla T4\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given data"
      ],
      "metadata": {
        "id": "yKpuYKgO_iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmKwlaCj_o-U",
        "outputId": "9f23d272-bc65-410d-9b39-7f9872f2bbdd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUVn2-x__z2z",
        "outputId": "5ed227dd-7ed9-40d2-810a-aab0b37e0ebb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"data/klue-sts-v1.1\")\n",
        "print(f\"My data directory : {_DATA_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5otTsnqV_6DY",
        "outputId": "35da2595-7a90-4246-e33c-a5dc029483f2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/NLP_project\n",
            "My data directory : /content/drive/MyDrive/NLP_project/data/klue-sts-v1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 내 json 불러오기\n",
        "df_train0 = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "df_test0 = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "XEnQbro_AFC3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape\n",
        "df_train0.shape, df_test0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4t-v3-EAdKr",
        "outputId": "70b9b1dc-8662-42e4-e6f7-a9ffd7fda888"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11668, 6), (519, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collected data"
      ],
      "metadata": {
        "id": "OkjYey9KAmwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bhuXo-IiMf1E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "mcNuklZsRJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['real-label']).hist(bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_oZuc4_sDF5B",
        "outputId": "f6b5e2a8-b732-48e8-df1b-a119e33a1fa9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f786e4eab50>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['sentence1'].map(lambda x: len(x)).hist()"
      ],
      "metadata": {
        "id": "mZHw4B4Ls3et",
        "outputId": "995b58e0-732e-4fa1-fbc7-e94893f0a91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7868a6e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['sentence2'].map(lambda x: len(x)).hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "qVQ_9azlPoBy",
        "outputId": "0b544805-66f7-46e4-f003-a8614c610ef2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7868968d90>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0[df_train0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "v7AhrCRiAi9b",
        "outputId": "0b841aa9-4432-4934-baa3-086de727ae41"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          guid      source  \\\n",
              "1514   klue-sts-v1_train_01514  policy-rtt   \n",
              "1661   klue-sts-v1_train_01661  airbnb-rtt   \n",
              "1715   klue-sts-v1_train_01715  airbnb-rtt   \n",
              "3872   klue-sts-v1_train_03872  policy-rtt   \n",
              "5139   klue-sts-v1_train_05139  policy-rtt   \n",
              "5292   klue-sts-v1_train_05292  policy-rtt   \n",
              "7045   klue-sts-v1_train_07045  policy-rtt   \n",
              "10908  klue-sts-v1_train_10908  policy-rtt   \n",
              "10939  klue-sts-v1_train_10939  policy-rtt   \n",
              "11112  klue-sts-v1_train_11112  policy-rtt   \n",
              "\n",
              "                                               sentence1  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "1661                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "1715                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "5139   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "7045   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10908  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10939  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "\n",
              "                                               sentence2  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "1661                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "1715                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "5139   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "7045   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10908  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10939  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "\n",
              "                                                  labels  \\\n",
              "1514   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "1661   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "1715   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "3872   {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "5139   {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "5292   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "7045   {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10908  {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10939  {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "11112  {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "\n",
              "                                             annotations  \n",
              "1514   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "1661   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "1715   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "3872   {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  \n",
              "5139   {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "5292   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "7045   {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10908  {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10939  {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "11112  {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a0689c0-2817-4621-8319-060c70fe5d25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>klue-sts-v1_train_01514</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>klue-sts-v1_train_01661</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>klue-sts-v1_train_01715</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>klue-sts-v1_train_03872</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5139</th>\n",
              "      <td>klue-sts-v1_train_05139</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5292</th>\n",
              "      <td>klue-sts-v1_train_05292</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7045</th>\n",
              "      <td>klue-sts-v1_train_07045</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10908</th>\n",
              "      <td>klue-sts-v1_train_10908</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10939</th>\n",
              "      <td>klue-sts-v1_train_10939</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11112</th>\n",
              "      <td>klue-sts-v1_train_11112</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a0689c0-2817-4621-8319-060c70fe5d25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a0689c0-2817-4621-8319-060c70fe5d25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a0689c0-2817-4621-8319-060c70fe5d25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test0[df_test0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "_yuCC-wKCnPr",
        "outputId": "222e0028-7dc4-4c3b-e79e-1f131a5f0446"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [guid, source, sentence1, sentence2, labels, annotations]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62d5c549-e6cb-4bf0-bd91-e4cd02566ce3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62d5c549-e6cb-4bf0-bd91-e4cd02566ce3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62d5c549-e6cb-4bf0-bd91-e4cd02566ce3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62d5c549-e6cb-4bf0-bd91-e4cd02566ce3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_train0.drop_duplicates(['sentence1','sentence2']),df_test0]).duplicated(['sentence1','sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKhRexrZC4aE",
        "outputId": "44e6a371-4d52-4910-9075-02919c664384"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0.isna().sum().sum()+df_test0.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Y9-rovDxnE",
        "outputId": "28527644-1397-41f7-c445-02b53e7d33f0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "ySxzpHXJQR1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "oTmY-YL5Lo_1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "2L3Qg_QqFKpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    def __init__(self,train,test):\n",
        "        self.train=train\n",
        "        self.test=test\n",
        "\n",
        "    def check_st(self, text):\n",
        "      text = re.sub('a-zA-Z一-龥㐀-䶵豈-龎[-=+,#/\\?:^$.@*\\\"※~&%ㆍ·!』\\\\‘〈〉|\\(\\)\\[\\]\\<\\>`\\'…》《]','', text)\n",
        "      return text\n",
        "    \n",
        "    def BERT_baseline(self):\n",
        "        train = self.train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "        sentence = train.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = train['labels'].map(lambda x: int(x['real-label']))\n",
        "        train = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence','label']\n",
        "        sentence = self.test.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = self.test['labels'].map(lambda x: int(x['real-label']))\n",
        "        test = pd.concat([sentence,label],axis=1)\n",
        "        test.columns = ['sentence','label']\n",
        "        return train, test\n",
        "\n",
        "    def BERT_round(self):\n",
        "        train = self.train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "        sentence = train.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = train['labels'].map(lambda x: round(x['real-label']))\n",
        "        train = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence','label']\n",
        "        sentence = self.test.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = self.test['labels'].map(lambda x: round(x['real-label']))\n",
        "        test = pd.concat([sentence,label],axis=1)\n",
        "        test.columns = ['sentence','label']\n",
        "        return train, test\n",
        "\n",
        "    def BERT_Siamese(self):\n",
        "        train = self.train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "        sentence = train[['sentence1','sentence2']]\n",
        "        label = train['labels'].map(lambda x: int(x['real-label']))\n",
        "        train = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence1','sentence2','label']\n",
        "        sentence = train[['sentence1','sentence2']]\n",
        "        label = self.test['labels'].map(lambda x: int(x['real-label']))\n",
        "        test = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence1','sentence2','label']\n",
        "        return train, test"
      ],
      "metadata": {
        "id": "jVwblZvZQXGI"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp=Preprocess(df_train0,df_test0)"
      ],
      "metadata": {
        "id": "cKSuoWq1e1Tt"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = pp.BERT_baseline()"
      ],
      "metadata": {
        "id": "u7hYDHWGCm0C"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fu8-BMqCC93p",
        "outputId": "3a6d06e1-e349-4aab-c747-ab783fd601b4"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  label\n",
              "0  숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. [SEP] 숙박시설의 위...      3\n",
              "1  위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다. ...      0\n",
              "2  회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘. [SEP] ...      0\n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...      0\n",
              "4  호스트의 답장이 늦으나, 개선될 것으로 보입니다. [SEP] 호스트 응답이 늦었지만...      4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ecfbf5a-efbf-4cdd-8ae6-d65f24e32802\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. [SEP] 숙박시설의 위...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘. [SEP] ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다. [SEP] 호스트 응답이 늦었지만...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ecfbf5a-efbf-4cdd-8ae6-d65f24e32802')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ecfbf5a-efbf-4cdd-8ae6-d65f24e32802 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ecfbf5a-efbf-4cdd-8ae6-d65f24e32802');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "id": "L0TceNfiy4ba",
        "outputId": "b66b98ab-b444-4ae1-99cc-e8a6758b8e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4350\n",
              "3    2852\n",
              "4    2698\n",
              "1     906\n",
              "2     810\n",
              "5      45\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ],
      "metadata": {
        "id": "IAIZB6y0kIyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nMHTC1mtkLKp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "DUsE3dGzTBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "nrxcSuANS3ua"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df_train.sentence.to_list(), df_train.label.to_list())\n",
        "test_dataset = CustomDataset(df_test.sentence.to_list(), df_test.label.to_list())"
      ],
      "metadata": {
        "id": "qHRSCsPX_XiU"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "_xnq7qO8VeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = df_train.shape[0] # train 전체 길이\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])"
      ],
      "metadata": {
        "id": "YhDSTrpoVhuM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid Dataset len: {len(valid_dataset)}\")\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VF0hHy_qbg",
        "outputId": "fa51cfca-5c97-4b53-9163-ce38ef02d3a8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10494\n",
            "Valid Dataset len: 1167\n",
            "Test Dataset len: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "PUZIdwDiW8Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Model"
      ],
      "metadata": {
        "id": "eX4B11HRFonl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/snaiws/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAJVTDRcerk",
        "outputId": "d9d09b47-96d4-452d-d2b5-11a5a8d178e5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NLP_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NLP_project.CustomModels.BERT_baseline import Bert_baseline"
      ],
      "metadata": {
        "id": "0NoUvfiIbibP"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ARGUMENT"
      ],
      "metadata": {
        "id": "Iz2aZrF5Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 58\n",
        "eval_batch_size = 64\n",
        "epochs=25\n",
        "patience=2\n",
        "\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "customModel = Bert_baseline(hidden_size=768, n_label=6)\n",
        "customOptimizer = AdamW(\n",
        "    customModel.parameters(), # update 대상 파라미터를 입력\n",
        "    lr=4.335281794951567e-06,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "id": "CiEIKbbuWgTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a3d1ce-4aa7-40c6-c420-692b0ee61575"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "gxJnvrXwWENj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "45DCZ7_5WGs4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = train_batch_size,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afNNT7crFH28",
        "outputId": "1f5c0ff7-f420-48f6-a646-e457ee20f6da"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 181\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializer"
      ],
      "metadata": {
        "id": "fb4K-Oo8Fc7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(model, optimizer, train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "i4omKhdSQfpJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "NwgtRhD4FhSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = os.path.abspath(os.curdir)\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "        file_name = f'{self.path}/model.ckpt.best'\n",
        "        \n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss' : loss\n",
        "            }, \n",
        "            file_name\n",
        "        )\n",
        "      \n",
        "        print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "xjTgaMgaJLIo"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate"
      ],
      "metadata": {
        "id": "fBx_gbpYFmSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc\n",
        "    "
      ],
      "metadata": {
        "id": "C21fot6EJNSL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XuwLP7lzepZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "    # early_stopping object의 초기화\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "    \n",
        "    # train_dataloaer 학습을 epochs만큼 반복\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "        \n",
        "        # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "        total_loss, batch_loss, batch_count = 0,0,0\n",
        "    \n",
        "        # model을 train 모드로 설정 & device 할당\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "        \n",
        "        # data iterator를 돌면서 하나씩 학습\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_count+=1\n",
        "            \n",
        "            # tensor 연산 전, 각 tensor에 device 할당\n",
        "            batch = tuple(item.to(device) for item in batch)\n",
        "        \n",
        "            batch_input, batch_label = batch\n",
        "        \n",
        "            # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "            model.zero_grad()\n",
        "        \n",
        "            # forward\n",
        "            logits = model(**batch_input)\n",
        "        \n",
        "            # loss\n",
        "            loss = loss_fct(logits, batch_label)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "            # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "            loss.backward()\n",
        "            \n",
        "            # gradient clipping 적용 \n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            # optimizer & scheduler 업데이트\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "            if (step % 10 == 0 and step != 0):\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                # reset \n",
        "                batch_loss, batch_count = 0,0\n",
        "        \n",
        "        print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "        print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "        \n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "            print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "        # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
        "        #  만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
        "        early_stopping(valid_loss, model, optimizer, scheduler, epoch)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "            \n",
        "            \n",
        "    print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kK09khnhJQfo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)\n",
        "train_model(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLtohXGJUJF",
        "outputId": "f55c5fa1-b732-476f-a02d-822209cb2386"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 25 epochs: 4525\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 4.3247429883782035e-06, Avg Loss : 1.8099\n",
            "Epoch: 1, Step : 20, LR : 4.315162255129692e-06, Avg Loss : 1.7474\n",
            "Epoch: 1, Step : 30, LR : 4.30558152188118e-06, Avg Loss : 1.7077\n",
            "Epoch: 1, Step : 40, LR : 4.296000788632668e-06, Avg Loss : 1.6527\n",
            "Epoch: 1, Step : 50, LR : 4.286420055384157e-06, Avg Loss : 1.5964\n",
            "Epoch: 1, Step : 60, LR : 4.276839322135645e-06, Avg Loss : 1.5426\n",
            "Epoch: 1, Step : 70, LR : 4.267258588887133e-06, Avg Loss : 1.4797\n",
            "Epoch: 1, Step : 80, LR : 4.257677855638622e-06, Avg Loss : 1.4529\n",
            "Epoch: 1, Step : 90, LR : 4.24809712239011e-06, Avg Loss : 1.3227\n",
            "Epoch: 1, Step : 100, LR : 4.238516389141598e-06, Avg Loss : 1.3617\n",
            "Epoch: 1, Step : 110, LR : 4.228935655893086e-06, Avg Loss : 1.3628\n",
            "Epoch: 1, Step : 120, LR : 4.219354922644575e-06, Avg Loss : 1.2882\n",
            "Epoch: 1, Step : 130, LR : 4.209774189396063e-06, Avg Loss : 1.2785\n",
            "Epoch: 1, Step : 140, LR : 4.200193456147551e-06, Avg Loss : 1.2416\n",
            "Epoch: 1, Step : 150, LR : 4.1906127228990394e-06, Avg Loss : 1.2461\n",
            "Epoch: 1, Step : 160, LR : 4.181031989650527e-06, Avg Loss : 1.2178\n",
            "Epoch: 1, Step : 170, LR : 4.171451256402015e-06, Avg Loss : 1.2512\n",
            "Epoch: 1, Step : 180, LR : 4.161870523153503e-06, Avg Loss : 1.2419\n",
            "Epoch 1 Total Mean Loss : 1.4355\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 1.1287 Valid Acc : 60.21\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "Saving epoch 1 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_1\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 4.151331716580141e-06, Avg Loss : 1.2419\n",
            "Epoch: 2, Step : 20, LR : 4.141750983331629e-06, Avg Loss : 1.2303\n",
            "Epoch: 2, Step : 30, LR : 4.132170250083117e-06, Avg Loss : 1.1392\n",
            "Epoch: 2, Step : 40, LR : 4.122589516834606e-06, Avg Loss : 1.1901\n",
            "Epoch: 2, Step : 50, LR : 4.113008783586094e-06, Avg Loss : 1.1631\n",
            "Epoch: 2, Step : 60, LR : 4.103428050337582e-06, Avg Loss : 1.1356\n",
            "Epoch: 2, Step : 70, LR : 4.093847317089071e-06, Avg Loss : 1.1200\n",
            "Epoch: 2, Step : 80, LR : 4.084266583840559e-06, Avg Loss : 1.1174\n",
            "Epoch: 2, Step : 90, LR : 4.074685850592047e-06, Avg Loss : 1.1150\n",
            "Epoch: 2, Step : 100, LR : 4.0651051173435355e-06, Avg Loss : 1.1854\n",
            "Epoch: 2, Step : 110, LR : 4.0555243840950234e-06, Avg Loss : 1.2137\n",
            "Epoch: 2, Step : 120, LR : 4.045943650846512e-06, Avg Loss : 1.1216\n",
            "Epoch: 2, Step : 130, LR : 4.036362917598e-06, Avg Loss : 1.1026\n",
            "Epoch: 2, Step : 140, LR : 4.026782184349488e-06, Avg Loss : 1.1155\n",
            "Epoch: 2, Step : 150, LR : 4.017201451100977e-06, Avg Loss : 1.0692\n",
            "Epoch: 2, Step : 160, LR : 4.007620717852465e-06, Avg Loss : 1.0603\n",
            "Epoch: 2, Step : 170, LR : 3.998039984603953e-06, Avg Loss : 1.0901\n",
            "Epoch: 2, Step : 180, LR : 3.988459251355442e-06, Avg Loss : 1.1002\n",
            "Epoch 2 Total Mean Loss : 1.1401\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 1.0442 Valid Acc : 61.73\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "Saving epoch 2 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 3.977920444782079e-06, Avg Loss : 1.0642\n",
            "Epoch: 3, Step : 20, LR : 3.968339711533567e-06, Avg Loss : 1.0810\n",
            "Epoch: 3, Step : 30, LR : 3.958758978285055e-06, Avg Loss : 1.1400\n",
            "Epoch: 3, Step : 40, LR : 3.949178245036543e-06, Avg Loss : 1.0245\n",
            "Epoch: 3, Step : 50, LR : 3.9395975117880315e-06, Avg Loss : 1.0717\n",
            "Epoch: 3, Step : 60, LR : 3.9300167785395195e-06, Avg Loss : 1.1072\n",
            "Epoch: 3, Step : 70, LR : 3.9204360452910075e-06, Avg Loss : 1.0729\n",
            "Epoch: 3, Step : 80, LR : 3.910855312042496e-06, Avg Loss : 1.0667\n",
            "Epoch: 3, Step : 90, LR : 3.901274578793984e-06, Avg Loss : 1.0525\n",
            "Epoch: 3, Step : 100, LR : 3.891693845545472e-06, Avg Loss : 1.1506\n",
            "Epoch: 3, Step : 110, LR : 3.882113112296961e-06, Avg Loss : 1.0428\n",
            "Epoch: 3, Step : 120, LR : 3.872532379048449e-06, Avg Loss : 1.0715\n",
            "Epoch: 3, Step : 130, LR : 3.862951645799937e-06, Avg Loss : 1.0093\n",
            "Epoch: 3, Step : 140, LR : 3.853370912551426e-06, Avg Loss : 1.0366\n",
            "Epoch: 3, Step : 150, LR : 3.843790179302914e-06, Avg Loss : 1.0669\n",
            "Epoch: 3, Step : 160, LR : 3.834209446054402e-06, Avg Loss : 1.0541\n",
            "Epoch: 3, Step : 170, LR : 3.824628712805891e-06, Avg Loss : 0.9845\n",
            "Epoch: 3, Step : 180, LR : 3.8150479795573786e-06, Avg Loss : 1.0082\n",
            "Epoch 3 Total Mean Loss : 1.0614\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 1.0232 Valid Acc : 61.81\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "Saving epoch 3 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_3\n",
            "*****Epoch 4 Train Start*****\n",
            "Epoch: 4, Step : 10, LR : 3.8045091729840155e-06, Avg Loss : 1.0644\n",
            "Epoch: 4, Step : 20, LR : 3.794928439735504e-06, Avg Loss : 1.1046\n",
            "Epoch: 4, Step : 30, LR : 3.7853477064869923e-06, Avg Loss : 0.9760\n",
            "Epoch: 4, Step : 40, LR : 3.7757669732384803e-06, Avg Loss : 1.0390\n",
            "Epoch: 4, Step : 50, LR : 3.7661862399899687e-06, Avg Loss : 1.0107\n",
            "Epoch: 4, Step : 60, LR : 3.756605506741457e-06, Avg Loss : 0.9528\n",
            "Epoch: 4, Step : 70, LR : 3.747024773492945e-06, Avg Loss : 1.0278\n",
            "Epoch: 4, Step : 80, LR : 3.7374440402444335e-06, Avg Loss : 0.9792\n",
            "Epoch: 4, Step : 90, LR : 3.7278633069959214e-06, Avg Loss : 1.0319\n",
            "Epoch: 4, Step : 100, LR : 3.71828257374741e-06, Avg Loss : 1.0541\n",
            "Epoch: 4, Step : 110, LR : 3.7087018404988982e-06, Avg Loss : 1.0689\n",
            "Epoch: 4, Step : 120, LR : 3.6991211072503862e-06, Avg Loss : 1.0491\n",
            "Epoch: 4, Step : 130, LR : 3.689540374001875e-06, Avg Loss : 1.0544\n",
            "Epoch: 4, Step : 140, LR : 3.679959640753363e-06, Avg Loss : 1.1022\n",
            "Epoch: 4, Step : 150, LR : 3.670378907504851e-06, Avg Loss : 0.9864\n",
            "Epoch: 4, Step : 160, LR : 3.66079817425634e-06, Avg Loss : 0.9984\n",
            "Epoch: 4, Step : 170, LR : 3.6512174410078278e-06, Avg Loss : 0.9725\n",
            "Epoch: 4, Step : 180, LR : 3.6416367077593158e-06, Avg Loss : 1.0215\n",
            "Epoch 4 Total Mean Loss : 1.0276\n",
            "*****Epoch 4 Train Finish*****\n",
            "\n",
            "*****Epoch 4 Valid Start*****\n",
            "Epoch 4 Valid Loss : 0.9979 Valid Acc : 61.96\n",
            "*****Epoch 4 Valid Finish*****\n",
            "\n",
            "Saving epoch 4 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_4\n",
            "*****Epoch 5 Train Start*****\n",
            "Epoch: 5, Step : 10, LR : 3.631097901185953e-06, Avg Loss : 0.9112\n",
            "Epoch: 5, Step : 20, LR : 3.621517167937441e-06, Avg Loss : 0.9748\n",
            "Epoch: 5, Step : 30, LR : 3.6119364346889295e-06, Avg Loss : 0.9941\n",
            "Epoch: 5, Step : 40, LR : 3.602355701440418e-06, Avg Loss : 1.0353\n",
            "Epoch: 5, Step : 50, LR : 3.592774968191906e-06, Avg Loss : 1.0282\n",
            "Epoch: 5, Step : 60, LR : 3.5831942349433943e-06, Avg Loss : 0.9964\n",
            "Epoch: 5, Step : 70, LR : 3.5736135016948827e-06, Avg Loss : 1.0506\n",
            "Epoch: 5, Step : 80, LR : 3.5640327684463706e-06, Avg Loss : 0.9429\n",
            "Epoch: 5, Step : 90, LR : 3.5544520351978586e-06, Avg Loss : 0.9577\n",
            "Epoch: 5, Step : 100, LR : 3.5448713019493474e-06, Avg Loss : 0.9600\n",
            "Epoch: 5, Step : 110, LR : 3.5352905687008354e-06, Avg Loss : 0.9803\n",
            "Epoch: 5, Step : 120, LR : 3.525709835452324e-06, Avg Loss : 1.0837\n",
            "Epoch: 5, Step : 130, LR : 3.5161291022038122e-06, Avg Loss : 0.9238\n",
            "Epoch: 5, Step : 140, LR : 3.5065483689553e-06, Avg Loss : 1.0464\n",
            "Epoch: 5, Step : 150, LR : 3.4969676357067886e-06, Avg Loss : 0.9740\n",
            "Epoch: 5, Step : 160, LR : 3.487386902458277e-06, Avg Loss : 0.9104\n",
            "Epoch: 5, Step : 170, LR : 3.477806169209765e-06, Avg Loss : 0.9719\n",
            "Epoch: 5, Step : 180, LR : 3.4682254359612534e-06, Avg Loss : 0.8720\n",
            "Epoch 5 Total Mean Loss : 0.9782\n",
            "*****Epoch 5 Train Finish*****\n",
            "\n",
            "*****Epoch 5 Valid Start*****\n",
            "Epoch 5 Valid Loss : 1.0082 Valid Acc : 61.88\n",
            "*****Epoch 5 Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 2\n",
            "*****Epoch 6 Train Start*****\n",
            "Epoch: 6, Step : 10, LR : 3.4576866293878903e-06, Avg Loss : 0.9451\n",
            "Epoch: 6, Step : 20, LR : 3.4481058961393783e-06, Avg Loss : 0.9266\n",
            "Epoch: 6, Step : 30, LR : 3.438525162890867e-06, Avg Loss : 0.9385\n",
            "Epoch: 6, Step : 40, LR : 3.428944429642355e-06, Avg Loss : 0.9863\n",
            "Epoch: 6, Step : 50, LR : 3.419363696393843e-06, Avg Loss : 0.9736\n",
            "Epoch: 6, Step : 60, LR : 3.409782963145332e-06, Avg Loss : 0.9957\n",
            "Epoch: 6, Step : 70, LR : 3.40020222989682e-06, Avg Loss : 0.9694\n",
            "Epoch: 6, Step : 80, LR : 3.390621496648308e-06, Avg Loss : 0.9290\n",
            "Epoch: 6, Step : 90, LR : 3.3810407633997967e-06, Avg Loss : 0.9359\n",
            "Epoch: 6, Step : 100, LR : 3.3714600301512846e-06, Avg Loss : 0.8757\n",
            "Epoch: 6, Step : 110, LR : 3.3618792969027726e-06, Avg Loss : 0.9499\n",
            "Epoch: 6, Step : 120, LR : 3.352298563654261e-06, Avg Loss : 0.9323\n",
            "Epoch: 6, Step : 130, LR : 3.3427178304057494e-06, Avg Loss : 0.9000\n",
            "Epoch: 6, Step : 140, LR : 3.333137097157238e-06, Avg Loss : 0.9240\n",
            "Epoch: 6, Step : 150, LR : 3.3235563639087258e-06, Avg Loss : 0.9709\n",
            "Epoch: 6, Step : 160, LR : 3.313975630660214e-06, Avg Loss : 0.9372\n",
            "Epoch: 6, Step : 170, LR : 3.3043948974117026e-06, Avg Loss : 0.9681\n",
            "Epoch: 6, Step : 180, LR : 3.2948141641631906e-06, Avg Loss : 0.9208\n",
            "Epoch 6 Total Mean Loss : 0.9433\n",
            "*****Epoch 6 Train Finish*****\n",
            "\n",
            "*****Epoch 6 Valid Start*****\n",
            "Epoch 6 Valid Loss : 0.9914 Valid Acc : 61.52\n",
            "*****Epoch 6 Valid Finish*****\n",
            "\n",
            "Saving epoch 6 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_6\n",
            "*****Epoch 7 Train Start*****\n",
            "Epoch: 7, Step : 10, LR : 3.2842753575898275e-06, Avg Loss : 0.8870\n",
            "Epoch: 7, Step : 20, LR : 3.2746946243413163e-06, Avg Loss : 0.9799\n",
            "Epoch: 7, Step : 30, LR : 3.2651138910928043e-06, Avg Loss : 0.9141\n",
            "Epoch: 7, Step : 40, LR : 3.2555331578442923e-06, Avg Loss : 0.9153\n",
            "Epoch: 7, Step : 50, LR : 3.2459524245957807e-06, Avg Loss : 0.9625\n",
            "Epoch: 7, Step : 60, LR : 3.236371691347269e-06, Avg Loss : 0.9679\n",
            "Epoch: 7, Step : 70, LR : 3.226790958098757e-06, Avg Loss : 0.8832\n",
            "Epoch: 7, Step : 80, LR : 3.2172102248502454e-06, Avg Loss : 0.8879\n",
            "Epoch: 7, Step : 90, LR : 3.207629491601734e-06, Avg Loss : 0.9213\n",
            "Epoch: 7, Step : 100, LR : 3.198048758353222e-06, Avg Loss : 0.9376\n",
            "Epoch: 7, Step : 110, LR : 3.18846802510471e-06, Avg Loss : 0.9247\n",
            "Epoch: 7, Step : 120, LR : 3.178887291856198e-06, Avg Loss : 0.9362\n",
            "Epoch: 7, Step : 130, LR : 3.1693065586076866e-06, Avg Loss : 0.9542\n",
            "Epoch: 7, Step : 140, LR : 3.159725825359175e-06, Avg Loss : 0.9856\n",
            "Epoch: 7, Step : 150, LR : 3.150145092110663e-06, Avg Loss : 0.8579\n",
            "Epoch: 7, Step : 160, LR : 3.1405643588621518e-06, Avg Loss : 0.9268\n",
            "Epoch: 7, Step : 170, LR : 3.1309836256136398e-06, Avg Loss : 0.8691\n",
            "Epoch: 7, Step : 180, LR : 3.1214028923651277e-06, Avg Loss : 0.9121\n",
            "Epoch 7 Total Mean Loss : 0.9233\n",
            "*****Epoch 7 Train Finish*****\n",
            "\n",
            "*****Epoch 7 Valid Start*****\n",
            "Epoch 7 Valid Loss : 0.9548 Valid Acc : 62.45\n",
            "*****Epoch 7 Valid Finish*****\n",
            "\n",
            "Saving epoch 7 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_7\n",
            "*****Epoch 8 Train Start*****\n",
            "Epoch: 8, Step : 10, LR : 3.110864085791765e-06, Avg Loss : 0.8752\n",
            "Epoch: 8, Step : 20, LR : 3.1012833525432535e-06, Avg Loss : 0.9669\n",
            "Epoch: 8, Step : 30, LR : 3.0917026192947415e-06, Avg Loss : 0.8867\n",
            "Epoch: 8, Step : 40, LR : 3.08212188604623e-06, Avg Loss : 0.8710\n",
            "Epoch: 8, Step : 50, LR : 3.072541152797718e-06, Avg Loss : 0.9266\n",
            "Epoch: 8, Step : 60, LR : 3.0629604195492062e-06, Avg Loss : 0.9647\n",
            "Epoch: 8, Step : 70, LR : 3.0533796863006946e-06, Avg Loss : 0.9360\n",
            "Epoch: 8, Step : 80, LR : 3.0437989530521826e-06, Avg Loss : 0.8202\n",
            "Epoch: 8, Step : 90, LR : 3.034218219803671e-06, Avg Loss : 0.9149\n",
            "Epoch: 8, Step : 100, LR : 3.0246374865551594e-06, Avg Loss : 0.8880\n",
            "Epoch: 8, Step : 110, LR : 3.0150567533066474e-06, Avg Loss : 0.8731\n",
            "Epoch: 8, Step : 120, LR : 3.0054760200581354e-06, Avg Loss : 0.8517\n",
            "Epoch: 8, Step : 130, LR : 2.995895286809624e-06, Avg Loss : 0.8783\n",
            "Epoch: 8, Step : 140, LR : 2.986314553561112e-06, Avg Loss : 0.8917\n",
            "Epoch: 8, Step : 150, LR : 2.9767338203126006e-06, Avg Loss : 0.9488\n",
            "Epoch: 8, Step : 160, LR : 2.967153087064089e-06, Avg Loss : 0.9373\n",
            "Epoch: 8, Step : 170, LR : 2.957572353815577e-06, Avg Loss : 0.9055\n",
            "Epoch: 8, Step : 180, LR : 2.9479916205670653e-06, Avg Loss : 0.8697\n",
            "Epoch 8 Total Mean Loss : 0.9002\n",
            "*****Epoch 8 Train Finish*****\n",
            "\n",
            "*****Epoch 8 Valid Start*****\n",
            "Epoch 8 Valid Loss : 0.9734 Valid Acc : 65.02\n",
            "*****Epoch 8 Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 2\n",
            "*****Epoch 9 Train Start*****\n",
            "Epoch: 9, Step : 10, LR : 2.9374528139937023e-06, Avg Loss : 0.8579\n",
            "Epoch: 9, Step : 20, LR : 2.9278720807451907e-06, Avg Loss : 0.8482\n",
            "Epoch: 9, Step : 30, LR : 2.918291347496679e-06, Avg Loss : 0.8940\n",
            "Epoch: 9, Step : 40, LR : 2.908710614248167e-06, Avg Loss : 0.9354\n",
            "Epoch: 9, Step : 50, LR : 2.899129880999655e-06, Avg Loss : 0.8520\n",
            "Epoch: 9, Step : 60, LR : 2.889549147751144e-06, Avg Loss : 0.8284\n",
            "Epoch: 9, Step : 70, LR : 2.879968414502632e-06, Avg Loss : 0.9105\n",
            "Epoch: 9, Step : 80, LR : 2.87038768125412e-06, Avg Loss : 0.8579\n",
            "Epoch: 9, Step : 90, LR : 2.8608069480056086e-06, Avg Loss : 0.8069\n",
            "Epoch: 9, Step : 100, LR : 2.8512262147570966e-06, Avg Loss : 0.8099\n",
            "Epoch: 9, Step : 110, LR : 2.8416454815085846e-06, Avg Loss : 0.9303\n",
            "Epoch: 9, Step : 120, LR : 2.8320647482600734e-06, Avg Loss : 0.8342\n",
            "Epoch: 9, Step : 130, LR : 2.8224840150115614e-06, Avg Loss : 0.8027\n",
            "Epoch: 9, Step : 140, LR : 2.8129032817630494e-06, Avg Loss : 0.8245\n",
            "Epoch: 9, Step : 150, LR : 2.8033225485145378e-06, Avg Loss : 0.8404\n",
            "Epoch: 9, Step : 160, LR : 2.793741815266026e-06, Avg Loss : 0.9702\n",
            "Epoch: 9, Step : 170, LR : 2.7841610820175145e-06, Avg Loss : 0.9388\n",
            "Epoch: 9, Step : 180, LR : 2.7745803487690025e-06, Avg Loss : 0.8152\n",
            "Epoch 9 Total Mean Loss : 0.8643\n",
            "*****Epoch 9 Train Finish*****\n",
            "\n",
            "*****Epoch 9 Valid Start*****\n",
            "Epoch 9 Valid Loss : 0.9807 Valid Acc : 66.32\n",
            "*****Epoch 9 Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            "Train Completed. End Program.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "GFiQGULKrxfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load checkpoint"
      ],
      "metadata": {
        "id": "4aim45otF4si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = input()\n",
        "checkpoint = torch.load(f'./model_ckpt_{best_epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4StQ5rCRPJt",
        "outputId": "13bae5bb-b45c-4b0e-bc3e-64d1c4f6e31a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSy2twvbRSHd",
        "outputId": "a71c8b0a-2ad5-4afc-a0e3-c0e28c8a9197"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOuSODA6RSQ9",
        "outputId": "993a5455-80d9-4745-ba52-e0b475001670"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoxlaI_RSTb",
        "outputId": "1b5e1e7d-f4d9-4410-dc8c-81032a7130db"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict and evaluate"
      ],
      "metadata": {
        "id": "w1uKfufLF8kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n"
      ],
      "metadata": {
        "id": "UhtXfy8kJvMR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "NQAuNkxRRdxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ea54d9-9d56-478e-f049-b7f91ff3982b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))"
      ],
      "metadata": {
        "id": "MjSIuizoaVg1"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from scipy.stats import pearsonr\n",
        "def evaluate(pred, test):\n",
        "    pred_binary = list(map(lambda x: 1 if x>=3 else 0, pred))\n",
        "    test_binary_label = list(map(lambda x: 1 if x>=3 else 0, test))\n",
        "    print(f'acc : {accuracy_score(test_binary_label, pred_binary)}')\n",
        "    print(f'f1 : {f1_score(test_binary_label, pred_binary)}')\n",
        "    print(f'pearson : {pearsonr(test, pred)}')\n",
        "    return f1_score(test_binary_label, pred_binary)\n",
        "    "
      ],
      "metadata": {
        "id": "r_CM_p_SzS3t"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv_HfFaARi6o",
        "outputId": "c91705b6-ae5d-4b65-9b3a-c470863f7441"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.7379576107899807\n",
            "f1 : 0.5903614457831325\n",
            "pearson : (0.6774412434544649, 5.7523813412947176e-71)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5903614457831325"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save outputs"
      ],
      "metadata": {
        "id": "UwfT52-LGDrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame(labels,columns=['pred_real_label'])\n",
        "filename = input()\n",
        "output.to_csv(f'{filename}.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOiLVeOGFay",
        "outputId": "b1083e19-263f-487d-a6d4-4d644370f1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_pred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G7e_OlKR4qni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model weights"
      ],
      "metadata": {
        "id": "ODz2YVO45-MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bert_baseline(hidden_size=768, n_label=6)"
      ],
      "metadata": {
        "id": "nNiDZphx5FXK",
        "outputId": "0ee120c1-cc92-4a8d-ce9b-4f7772b7bb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "rG_D-WBV5kMU",
        "outputId": "4effe6e2-a9ea-46d8-ecf4-c442a3939ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))\n",
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "id": "vzg0kIpZ5z66",
        "outputId": "4961f688-3c8b-4f89-94fc-ac026e7fe063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.7533718689788054\n",
            "f1 : 0.7697841726618705\n",
            "pearson : (0.7789983354145806, 7.071859924703616e-107)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZDS8IJNaVyB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "C91sdB_P6Cym",
        "outputId": "e1dc356d-9497-4805-ac7e-65fd11cf509b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "YrDmE0uyMjvu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optuna_train(model, optimizer):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "        model.zero_grad()\n",
        "        logits = model(**batch_input)\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "QJT780IPACjs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):  # `trial` is an object passed by Optuna.\n",
        "    train_batch_size = trial.suggest_int(\"train_batch_size\",24,64)\n",
        "    lr = trial.suggest_float(\"lr\",1e-6,1e-3,log=True)\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset),\n",
        "        collate_fn = custom_collate_fn\n",
        "    )\n",
        "\n",
        "\n",
        "    model = Bert_baseline(hidden_size=768, n_label=6)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr = lr\n",
        "        )\n",
        "    val_list = []\n",
        "    for epoch in range(4):\n",
        "        optuna_train(model,optimizer)\n",
        "        valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "        print(f'val_los : {valid_loss}')\n",
        "        trial.report(valid_loss, step = epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "        val_list.append(valid_loss)\n",
        "    return min(val_list)"
      ],
      "metadata": {
        "id": "jksNuvvL6C03"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=seed),\n",
        "    pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, \n",
        "        max_resource=4, \n",
        "        reduction_factor=3\n",
        "    ))\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "KuKNaaDS6C56",
        "outputId": "9b0bfbb0-50ab-4e64-b89e-c8fc1f34a0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 07:24:53,516]\u001b[0m A new study created in memory with name: no-name-d305b776-0710-457d-b411-96195e76df44\u001b[0m\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.4368336514422768\n",
            "val_los : 1.4357173693807501\n",
            "val_los : 1.4345683612321551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 07:35:50,698]\u001b[0m Trial 0 finished with value: 1.4345683612321551 and parameters: {'train_batch_size': 39, 'lr': 0.0007114476009343421}. Best is trial 0 with value: 1.4345683612321551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.4349377280787419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 0.9282781450371993\n",
            "val_los : 0.9060067063883731\n",
            "val_los : 0.9260139308477703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 07:46:50,150]\u001b[0m Trial 1 finished with value: 0.9060067063883731 and parameters: {'train_batch_size': 54, 'lr': 6.251373574521755e-05}. Best is trial 1 with value: 0.9060067063883731.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 0.9479707071655675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.121367495310934\n",
            "val_los : 0.9017338344925329\n",
            "val_los : 0.8365192821151332\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 07:57:50,584]\u001b[0m Trial 2 finished with value: 0.8254518006977282 and parameters: {'train_batch_size': 30, 'lr': 2.9375384576328313e-06}. Best is trial 2 with value: 0.8254518006977282.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 0.8254518006977282\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.6553459669414319\n",
            "val_los : 1.6069970695595992\n",
            "val_los : 1.5698014372273494\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 08:08:16,231]\u001b[0m Trial 3 pruned. \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.541549889664901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.1715391372379504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 08:13:46,041]\u001b[0m Trial 4 pruned. \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.0899092743271275\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.4338961965159367\n",
            "val_los : 1.442325748895344\n",
            "val_los : 1.436846846028378\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-30 08:24:45,220]\u001b[0m Trial 5 pruned. \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_los : 1.4334190707457692\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_los : 0.7546168408895794\n",
            "val_los : 0.6903386617961683\n",
            "val_los : 0.6775528286632738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-30 08:35:45,936]\u001b[0m Trial 6 finished with value: 0.6775528286632738 and parameters: {'train_batch_size': 58, 'lr': 4.335281794951567e-06}. Best is trial 6 with value: 0.6775528286632738.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_los : 0.6776950265231886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c54dd04947b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ))\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-e50c4b45575a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptima_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'val_los : {valid_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-38fc17103e5c>\u001b[0m in \u001b[0;36moptima_train\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Minimum objective value: ' + str(study.best_value))\n",
        "print('Best parameter: ' + str(study.best_params))"
      ],
      "metadata": {
        "id": "QarUZ2Vm6C3c",
        "outputId": "b87790be-fd26-448b-f0c2-a81f18dc638a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-d33a5a21f9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minimum objective value: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameter: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mbest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbest_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mbest_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    }
  ]
}