{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n"
      ],
      "metadata": {
        "id": "8hCnA1B7QRwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and data"
      ],
      "metadata": {
        "id": "z-Fu_ivvQRzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "esiGYeXTIVe5",
        "outputId": "d7184387-58da-41e9-af38-7bb1a45f3f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "id": "X17u4TxWQgZB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "DUUwmST90CEW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "sJSrVKyw0EOk",
        "outputId": "3f25b745-cb6b-473e-c4a5-f5f0c9d243cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "dxd6gSy8v1F0",
        "outputId": "2b21a762-95cb-4a10-b294-9c77c3331819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/NLP_project\""
      ],
      "metadata": {
        "id": "RzLQjQ_ywFk-",
        "outputId": "71929b84-a508-4ea3-baab-118c529b57c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"klue-sts-v1.1\")"
      ],
      "metadata": {
        "id": "wik2PXw-wNN5",
        "outputId": "4d5de97d-7f07-47b6-fe78-a612ae48af40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "test = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "_X-5km4NwTQJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, test.shape)\n",
        "print(train.columns)\n",
        "print(test.columns)"
      ],
      "metadata": {
        "id": "Hq9Fsmcz0VC0",
        "outputId": "054cb4b8-7161-44ee-ff53-da924f4506c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11668, 6) (519, 6)\n",
            "Index(['guid', 'source', 'sentence1', 'sentence2', 'labels', 'annotations'], dtype='object')\n",
            "Index(['guid', 'source', 'sentence1', 'sentence2', 'labels', 'annotations'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['sentence1','sentence2','labels']]\n",
        "train['labels'] = train['labels'].map(lambda x: round(x['real-label']))\n",
        "test = test[['sentence1','sentence2','labels']]\n",
        "test['labels'] = test['labels'].map(lambda x: round(x['real-label']))"
      ],
      "metadata": {
        "id": "u7hYDHWGCm0C",
        "outputId": "cabb29d6-b625-46cc-e7a6-e7c19cf24863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "fu8-BMqCC93p",
        "outputId": "06f3a8d3-316c-45ca-f1d8-46b8368d832d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0                   숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.   \n",
              "1      위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.   \n",
              "2            회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.   \n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...   \n",
              "4                        호스트의 답장이 늦으나, 개선될 것으로 보입니다.   \n",
              "\n",
              "                                    sentence2  labels  \n",
              "0  숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.       4  \n",
              "1       시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.       0  \n",
              "2                  사람들이 주로 네이버 메일을 쓰는 이유를 알려줘       0  \n",
              "3   고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.       1  \n",
              "4                  호스트 응답이 늦었지만 개선될 것으로 보입니다.       5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-738a7598-5df2-4191-b87b-63d6dc324229\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.</td>\n",
              "      <td>숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.</td>\n",
              "      <td>시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.</td>\n",
              "      <td>사람들이 주로 네이버 메일을 쓰는 이유를 알려줘</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다.</td>\n",
              "      <td>호스트 응답이 늦었지만 개선될 것으로 보입니다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-738a7598-5df2-4191-b87b-63d6dc324229')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-738a7598-5df2-4191-b87b-63d6dc324229 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-738a7598-5df2-4191-b87b-63d6dc324229');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['labels'].hist(bins=50)"
      ],
      "metadata": {
        "id": "_oZuc4_sDF5B",
        "outputId": "b438dfdc-8ac5-41b9-a279-2bd4ec5c36ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f982815c410>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "ySxzpHXJQR1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "75QHeIiL-_73"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train.sentence1.to_list(), train.labels.to_list())\n",
        "test_dataset = CustomDataset(test.sentence1.to_list(), test.labels.to_list())\n",
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n",
        "\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")\n",
        "print(f\"Test Dataset 1st element: {test_dataset[0]}\")"
      ],
      "metadata": {
        "id": "qHRSCsPX_XiU",
        "outputId": "4d443243-1d5b-4172-a957-a512cf8bea9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 11668\n",
            "Train Dataset 1st element: ('숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.', 4)\n",
            "Test Dataset len: 519\n",
            "Test Dataset 1st element: ('무엇보다도 호스트분들이 너무 친절하셨습니다.', 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = train.shape[0]\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train, [n_train, n_valid])\n",
        "\n",
        "print(f\"Train dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset len: {len(valid_dataset)}\")"
      ],
      "metadata": {
        "id": "N3VF0hHy_qbg",
        "outputId": "2c774a64-3dae-4f90-93fb-0e53a574f6ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset len: 10501\n",
            "Valid dataset len: 1167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "    \n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer_bert(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "tOWkWV9L_M-z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 구현\n",
        "train_batch_size = 32\n",
        "valid_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = train_batch_size,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = valid_batch_size,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = valid_batch_size,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ],
      "metadata": {
        "id": "afNNT7crFH28",
        "outputId": "86fe5867-10b2-49c5-93f3-7811ee0b774f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 329\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "5CZkR0r1QSBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import torch.nn as nn\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule"
      ],
      "metadata": {
        "id": "gmpdF8q-IEUg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Classifer\n",
        "class CustomClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int, n_label: int, freeze_base: bool = False):\n",
        "        super(CustomClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n",
        "\n",
        "        if freeze_base:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad=False\n",
        "\n",
        "        dropout_rate = 0.1\n",
        "        linear_layer_hidden_size = 32\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(linear_layer_hidden_size, n_label)\n",
        "        )\n",
        "\n",
        "    \n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n",
        "        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n",
        "\n",
        "        logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "7Y47FP6B_QmC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    \n",
        "    model = CustomClassifier(hidden_size=768, n_label=5)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(), # update 대상 파라미터를 입력\n",
        "        lr=2e-5,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "i4omKhdSQfpJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    \n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "xjTgaMgaJLIo"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc"
      ],
      "metadata": {
        "id": "C21fot6EJNSL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 \n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "            \n",
        "            # checkpoint 저장\n",
        "            save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kK09khnhJQfo"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fct = CrossEntropyLoss()\n",
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "id": "4QLtohXGJUJF",
        "outputId": "f2719384-8ec1-4edd-f697-e6abb5363f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 4 epochs: 1316\n",
            "*****Epoch 0 Train Start*****\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 7159",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-1252e5f543d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-100900f8404a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, valid_dataloader, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# data iterator를 돌면서 하나씩 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mbatch_count\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 7159"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "GFiQGULKrxfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('model.ckpt.2')"
      ],
      "metadata": {
        "id": "I4StQ5rCRPJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.keys()"
      ],
      "metadata": {
        "id": "HSy2twvbRSHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)"
      ],
      "metadata": {
        "id": "kOuSODA6RSQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "id": "AAoxlaI_RSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n"
      ],
      "metadata": {
        "id": "UhtXfy8kJvMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "NQAuNkxRRdxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def get_f1(true, pred):\n",
        "    return f1_score(true, pred)"
      ],
      "metadata": {
        "id": "r_CM_p_SzS3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_f1(labels, probs)"
      ],
      "metadata": {
        "id": "Sv_HfFaARi6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "STS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}