{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/NLP_project/blob/hyperparametertuner/STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n",
        "\n"
      ],
      "metadata": {
        "id": "3qfGz4Pa-Whu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "6R8hyvUu-1sK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sw7ilyV-KU8",
        "outputId": "36607be4-23d6-4299-a740-b392a26e14d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,  RandomSampler, SequentialSampler, random_split\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "kpKhz3Xi_A2j"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZepTYxNV_QPi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJA6wul9_SI3",
        "outputId": "c050a3bb-7a18-4163-c83e-05e64f620ea2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given data"
      ],
      "metadata": {
        "id": "yKpuYKgO_iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmKwlaCj_o-U",
        "outputId": "9095dbfc-0021-4330-af25-8adeba8ddee8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUVn2-x__z2z",
        "outputId": "35993ec6-1367-4897-db35-84252f0b6340"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"data/klue-sts-v1.1\")\n",
        "print(f\"My data directory : {_DATA_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5otTsnqV_6DY",
        "outputId": "a00d7a6c-2859-4f78-f44e-8d950329faf4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/NLP_project\n",
            "My data directory : /content/drive/MyDrive/NLP_project/data/klue-sts-v1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 내 json 불러오기\n",
        "df_train0 = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "df_test0 = pd.read_json('./klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "XEnQbro_AFC3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape\n",
        "df_train0.shape, df_test0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4t-v3-EAdKr",
        "outputId": "4cafe0c6-c469-4604-f0f5-3ca699656604"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11668, 6), (519, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collected data"
      ],
      "metadata": {
        "id": "OkjYey9KAmwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bhuXo-IiMf1E"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "mcNuklZsRJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['real-label']).hist(bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_oZuc4_sDF5B",
        "outputId": "ff7808f6-7f22-4b02-fe9b-672df818850c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe637b08e90>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['sentence1'].map(lambda x: len(x)).hist()"
      ],
      "metadata": {
        "id": "mZHw4B4Ls3et",
        "outputId": "1b96a4a9-6c4d-4137-b639-fc4ce205dc30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6372df310>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['sentence2'].map(lambda x: len(x)).hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "qVQ_9azlPoBy",
        "outputId": "4ea6f08c-2db5-4166-f6c2-48ddaf6a9bbf"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe63878bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0[df_train0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "v7AhrCRiAi9b",
        "outputId": "44db6645-ca0d-420b-9fa3-225fd6d1bda3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          guid      source  \\\n",
              "1514   klue-sts-v1_train_01514  policy-rtt   \n",
              "1661   klue-sts-v1_train_01661  airbnb-rtt   \n",
              "1715   klue-sts-v1_train_01715  airbnb-rtt   \n",
              "3872   klue-sts-v1_train_03872  policy-rtt   \n",
              "5139   klue-sts-v1_train_05139  policy-rtt   \n",
              "5292   klue-sts-v1_train_05292  policy-rtt   \n",
              "7045   klue-sts-v1_train_07045  policy-rtt   \n",
              "10908  klue-sts-v1_train_10908  policy-rtt   \n",
              "10939  klue-sts-v1_train_10939  policy-rtt   \n",
              "11112  klue-sts-v1_train_11112  policy-rtt   \n",
              "\n",
              "                                               sentence1  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "1661                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "1715                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "5139   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "7045   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10908  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10939  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "\n",
              "                                               sentence2  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "1661                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "1715                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "5139   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "7045   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10908  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10939  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "\n",
              "                                                  labels  \\\n",
              "1514   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "1661   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "1715   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "3872   {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "5139   {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "5292   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "7045   {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10908  {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10939  {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "11112  {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "\n",
              "                                             annotations  \n",
              "1514   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "1661   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "1715   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "3872   {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  \n",
              "5139   {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "5292   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "7045   {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10908  {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10939  {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "11112  {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-146a8a74-b6b2-45d2-8fc7-e9b908d904b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>klue-sts-v1_train_01514</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>klue-sts-v1_train_01661</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>klue-sts-v1_train_01715</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>klue-sts-v1_train_03872</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5139</th>\n",
              "      <td>klue-sts-v1_train_05139</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5292</th>\n",
              "      <td>klue-sts-v1_train_05292</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7045</th>\n",
              "      <td>klue-sts-v1_train_07045</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10908</th>\n",
              "      <td>klue-sts-v1_train_10908</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10939</th>\n",
              "      <td>klue-sts-v1_train_10939</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11112</th>\n",
              "      <td>klue-sts-v1_train_11112</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-146a8a74-b6b2-45d2-8fc7-e9b908d904b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-146a8a74-b6b2-45d2-8fc7-e9b908d904b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-146a8a74-b6b2-45d2-8fc7-e9b908d904b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test0[df_test0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "_yuCC-wKCnPr",
        "outputId": "79dd66e9-27dc-456a-8a27-e277e99e4ea4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [guid, source, sentence1, sentence2, labels, annotations]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10aa2569-9ac1-4e94-a497-22e0f163f84d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10aa2569-9ac1-4e94-a497-22e0f163f84d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10aa2569-9ac1-4e94-a497-22e0f163f84d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10aa2569-9ac1-4e94-a497-22e0f163f84d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_train0.drop_duplicates(['sentence1','sentence2']),df_test0]).duplicated(['sentence1','sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKhRexrZC4aE",
        "outputId": "72fd8c59-dcca-4dc4-832c-43c1958283d1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0.isna().sum().sum()+df_test0.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Y9-rovDxnE",
        "outputId": "df1ebf15-56a6-438a-b3f9-39cb82ee1aed"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "ySxzpHXJQR1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "oTmY-YL5Lo_1"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "2L3Qg_QqFKpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    def __init__(self,train,test):\n",
        "        self.train=train\n",
        "        self.test=test\n",
        "\n",
        "    def check_st(self, text):\n",
        "      text = re.sub('a-zA-Z一-龥㐀-䶵豈-龎[-=+,#/\\?:^$.@*\\\"※~&%ㆍ·!』\\\\‘〈〉|\\(\\)\\[\\]\\<\\>`\\'…》《]','', text)\n",
        "      return text\n",
        "    \n",
        "    def BERT_baseline(self):\n",
        "        train = self.train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "        sentence = train.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = train['labels'].map(lambda x: int(x['real-label']))\n",
        "        train = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence','label']\n",
        "        sentence = self.test.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = self.test['labels'].map(lambda x: int(x['real-label']))\n",
        "        test = pd.concat([sentence,label],axis=1)\n",
        "        test.columns = ['sentence','label']\n",
        "        return train, test\n",
        "\n",
        "    def BERT_round(self):\n",
        "        train = self.train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "        sentence = train.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = train['labels'].map(lambda x: round(x['real-label']))\n",
        "        train = pd.concat([sentence,label],axis=1)\n",
        "        train.columns = ['sentence','label']\n",
        "        sentence = self.test.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "        label = self.test['labels'].map(lambda x: round(x['real-label']))\n",
        "        test = pd.concat([sentence,label],axis=1)\n",
        "        test.columns = ['sentence','label']\n",
        "        return train, test"
      ],
      "metadata": {
        "id": "jVwblZvZQXGI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp=Preprocess(df_train0,df_test0)"
      ],
      "metadata": {
        "id": "cKSuoWq1e1Tt"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = pp.BERT_baseline()"
      ],
      "metadata": {
        "id": "u7hYDHWGCm0C"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fu8-BMqCC93p",
        "outputId": "edfc0917-3ed5-4a21-e5b9-0094e658428c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  label\n",
              "0  숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. [SEP] 숙박시설의 위...      3\n",
              "1  위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다. ...      0\n",
              "2  회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘. [SEP] ...      0\n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...      0\n",
              "4  호스트의 답장이 늦으나, 개선될 것으로 보입니다. [SEP] 호스트 응답이 늦었지만...      4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cea1bada-39b6-44e8-b457-5b9f02f72cec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. [SEP] 숙박시설의 위...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘. [SEP] ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다. [SEP] 호스트 응답이 늦었지만...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cea1bada-39b6-44e8-b457-5b9f02f72cec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cea1bada-39b6-44e8-b457-5b9f02f72cec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cea1bada-39b6-44e8-b457-5b9f02f72cec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "id": "L0TceNfiy4ba",
        "outputId": "f4fb0008-a72d-452c-dd95-810690a4b6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4350\n",
              "3    2852\n",
              "4    2698\n",
              "1     906\n",
              "2     810\n",
              "5      45\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ],
      "metadata": {
        "id": "IAIZB6y0kIyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nMHTC1mtkLKp"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "DUsE3dGzTBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "nrxcSuANS3ua"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df_train.sentence.to_list(), df_train.label.to_list())\n",
        "test_dataset = CustomDataset(df_test.sentence.to_list(), df_test.label.to_list())"
      ],
      "metadata": {
        "id": "qHRSCsPX_XiU"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "_xnq7qO8VeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = df_train.shape[0] # train 전체 길이\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])"
      ],
      "metadata": {
        "id": "YhDSTrpoVhuM"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid Dataset len: {len(valid_dataset)}\")\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VF0hHy_qbg",
        "outputId": "7e157b5c-52ba-480a-97e2-e1e2552de9c5"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10494\n",
            "Valid Dataset len: 1167\n",
            "Test Dataset len: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "PUZIdwDiW8Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Model"
      ],
      "metadata": {
        "id": "eX4B11HRFonl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/snaiws/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAJVTDRcerk",
        "outputId": "e44df418-4b30-414c-81f2-f3c884787b87"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NLP_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NLP_project.CustomModels.BERT_baseline import Bert_baseline"
      ],
      "metadata": {
        "id": "0NoUvfiIbibP"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ARGUMENT"
      ],
      "metadata": {
        "id": "Iz2aZrF5Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 64\n",
        "epochs=4\n",
        "patience=1\n",
        "\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "customModel = Bert_baseline(hidden_size=768, n_label=6)\n",
        "customOptimizer = AdamW(\n",
        "    customModel.parameters(), # update 대상 파라미터를 입력\n",
        "    lr=2e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "id": "CiEIKbbuWgTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63150a18-97fc-4a7a-e7ff-075856101b77"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "gxJnvrXwWENj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "45DCZ7_5WGs4"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = train_batch_size,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afNNT7crFH28",
        "outputId": "44e0fb26-e198-4a46-f106-68e14ace750d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 328\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializer"
      ],
      "metadata": {
        "id": "fb4K-Oo8Fc7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(model, optimizer, train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "i4omKhdSQfpJ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "NwgtRhD4FhSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = os.path.abspath(os.curdir)\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "        file_name = f'{self.path}/model_ckpt_{epoch}'\n",
        "        \n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss' : loss\n",
        "            }, \n",
        "            file_name\n",
        "        )\n",
        "      \n",
        "        print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "xjTgaMgaJLIo"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validate"
      ],
      "metadata": {
        "id": "fBx_gbpYFmSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc\n",
        "    "
      ],
      "metadata": {
        "id": "C21fot6EJNSL"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XuwLP7lzepZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "        # early_stopping object의 초기화\n",
        "        early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 \n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "            \n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "            # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
        "            #  만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
        "            early_stopping(valid_loss, model, optimizer, scheduler, epoch)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "                \n",
        "            # checkpoint 저장\n",
        "            early_stopping.save_checkpoint(model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kK09khnhJQfo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)\n",
        "train_model(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLtohXGJUJF",
        "outputId": "12059914-e8e0-47fe-d662-ea13294eb046"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 4 epochs: 1312\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 1.9832317073170734e-05, Avg Loss : 1.7822\n",
            "Epoch: 1, Step : 20, LR : 1.967987804878049e-05, Avg Loss : 1.6527\n",
            "Epoch: 1, Step : 30, LR : 1.9527439024390245e-05, Avg Loss : 1.5382\n",
            "Epoch: 1, Step : 40, LR : 1.9375e-05, Avg Loss : 1.3295\n",
            "Epoch: 1, Step : 50, LR : 1.922256097560976e-05, Avg Loss : 1.2992\n",
            "Epoch: 1, Step : 60, LR : 1.9070121951219514e-05, Avg Loss : 1.2381\n",
            "Epoch: 1, Step : 70, LR : 1.891768292682927e-05, Avg Loss : 1.2564\n",
            "Epoch: 1, Step : 80, LR : 1.8765243902439025e-05, Avg Loss : 1.2593\n",
            "Epoch: 1, Step : 90, LR : 1.8612804878048783e-05, Avg Loss : 1.1673\n",
            "Epoch: 1, Step : 100, LR : 1.846036585365854e-05, Avg Loss : 1.1602\n",
            "Epoch: 1, Step : 110, LR : 1.8307926829268294e-05, Avg Loss : 1.1707\n",
            "Epoch: 1, Step : 120, LR : 1.815548780487805e-05, Avg Loss : 1.2081\n",
            "Epoch: 1, Step : 130, LR : 1.8003048780487808e-05, Avg Loss : 1.1373\n",
            "Epoch: 1, Step : 140, LR : 1.7850609756097563e-05, Avg Loss : 1.1288\n",
            "Epoch: 1, Step : 150, LR : 1.7698170731707318e-05, Avg Loss : 1.0916\n",
            "Epoch: 1, Step : 160, LR : 1.7545731707317074e-05, Avg Loss : 1.0855\n",
            "Epoch: 1, Step : 170, LR : 1.739329268292683e-05, Avg Loss : 1.0855\n",
            "Epoch: 1, Step : 180, LR : 1.7240853658536588e-05, Avg Loss : 1.0943\n",
            "Epoch: 1, Step : 190, LR : 1.7088414634146343e-05, Avg Loss : 1.1829\n",
            "Epoch: 1, Step : 200, LR : 1.6935975609756098e-05, Avg Loss : 1.2265\n",
            "Epoch: 1, Step : 210, LR : 1.6783536585365857e-05, Avg Loss : 1.0539\n",
            "Epoch: 1, Step : 220, LR : 1.6631097560975612e-05, Avg Loss : 1.0287\n",
            "Epoch: 1, Step : 230, LR : 1.6478658536585367e-05, Avg Loss : 1.0417\n",
            "Epoch: 1, Step : 240, LR : 1.6326219512195123e-05, Avg Loss : 1.1012\n",
            "Epoch: 1, Step : 250, LR : 1.617378048780488e-05, Avg Loss : 1.0747\n",
            "Epoch: 1, Step : 260, LR : 1.6021341463414633e-05, Avg Loss : 1.1087\n",
            "Epoch: 1, Step : 270, LR : 1.5868902439024392e-05, Avg Loss : 1.0039\n",
            "Epoch: 1, Step : 280, LR : 1.5716463414634147e-05, Avg Loss : 1.1210\n",
            "Epoch: 1, Step : 290, LR : 1.5564024390243902e-05, Avg Loss : 1.0686\n",
            "Epoch: 1, Step : 300, LR : 1.541158536585366e-05, Avg Loss : 1.0777\n",
            "Epoch: 1, Step : 310, LR : 1.5259146341463416e-05, Avg Loss : 1.0810\n",
            "Epoch: 1, Step : 320, LR : 1.5106707317073173e-05, Avg Loss : 1.1018\n",
            "Epoch 1 Total Mean Loss : 1.1853\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.9764 Valid Acc : 61.30\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "Saving epoch 1 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_1\n",
            "Saving epoch 1 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_1\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 1.4832317073170733e-05, Avg Loss : 1.1324\n",
            "Epoch: 2, Step : 20, LR : 1.467987804878049e-05, Avg Loss : 0.9037\n",
            "Epoch: 2, Step : 30, LR : 1.4527439024390243e-05, Avg Loss : 1.0308\n",
            "Epoch: 2, Step : 40, LR : 1.4375e-05, Avg Loss : 1.0323\n",
            "Epoch: 2, Step : 50, LR : 1.4222560975609757e-05, Avg Loss : 1.0091\n",
            "Epoch: 2, Step : 60, LR : 1.4070121951219513e-05, Avg Loss : 0.8630\n",
            "Epoch: 2, Step : 70, LR : 1.391768292682927e-05, Avg Loss : 1.0775\n",
            "Epoch: 2, Step : 80, LR : 1.3765243902439025e-05, Avg Loss : 0.9418\n",
            "Epoch: 2, Step : 90, LR : 1.3612804878048782e-05, Avg Loss : 1.0050\n",
            "Epoch: 2, Step : 100, LR : 1.3460365853658537e-05, Avg Loss : 0.9416\n",
            "Epoch: 2, Step : 110, LR : 1.3307926829268294e-05, Avg Loss : 0.9791\n",
            "Epoch: 2, Step : 120, LR : 1.315548780487805e-05, Avg Loss : 0.8660\n",
            "Epoch: 2, Step : 130, LR : 1.3003048780487806e-05, Avg Loss : 0.9951\n",
            "Epoch: 2, Step : 140, LR : 1.2850609756097563e-05, Avg Loss : 0.9317\n",
            "Epoch: 2, Step : 150, LR : 1.2698170731707317e-05, Avg Loss : 1.0175\n",
            "Epoch: 2, Step : 160, LR : 1.2545731707317074e-05, Avg Loss : 0.9805\n",
            "Epoch: 2, Step : 170, LR : 1.239329268292683e-05, Avg Loss : 1.0053\n",
            "Epoch: 2, Step : 180, LR : 1.2240853658536586e-05, Avg Loss : 0.9995\n",
            "Epoch: 2, Step : 190, LR : 1.2088414634146342e-05, Avg Loss : 1.0095\n",
            "Epoch: 2, Step : 200, LR : 1.1935975609756099e-05, Avg Loss : 1.0033\n",
            "Epoch: 2, Step : 210, LR : 1.1783536585365856e-05, Avg Loss : 0.9632\n",
            "Epoch: 2, Step : 220, LR : 1.163109756097561e-05, Avg Loss : 0.9725\n",
            "Epoch: 2, Step : 230, LR : 1.1478658536585368e-05, Avg Loss : 0.9059\n",
            "Epoch: 2, Step : 240, LR : 1.1326219512195123e-05, Avg Loss : 1.0151\n",
            "Epoch: 2, Step : 250, LR : 1.117378048780488e-05, Avg Loss : 0.8970\n",
            "Epoch: 2, Step : 260, LR : 1.1021341463414634e-05, Avg Loss : 0.9035\n",
            "Epoch: 2, Step : 270, LR : 1.086890243902439e-05, Avg Loss : 0.9469\n",
            "Epoch: 2, Step : 280, LR : 1.0716463414634146e-05, Avg Loss : 0.8791\n",
            "Epoch: 2, Step : 290, LR : 1.0564024390243903e-05, Avg Loss : 0.8284\n",
            "Epoch: 2, Step : 300, LR : 1.041158536585366e-05, Avg Loss : 0.9729\n",
            "Epoch: 2, Step : 310, LR : 1.0259146341463415e-05, Avg Loss : 0.9097\n",
            "Epoch: 2, Step : 320, LR : 1.0106707317073172e-05, Avg Loss : 0.8780\n",
            "Epoch 2 Total Mean Loss : 0.9647\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.9597 Valid Acc : 68.89\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "Saving epoch 2 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_2\n",
            "Saving epoch 2 checkpoint at /content/drive/MyDrive/NLP_project/model_ckpt_2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 9.832317073170733e-06, Avg Loss : 0.8297\n",
            "Epoch: 3, Step : 20, LR : 9.679878048780489e-06, Avg Loss : 0.8683\n",
            "Epoch: 3, Step : 30, LR : 9.527439024390246e-06, Avg Loss : 0.8954\n",
            "Epoch: 3, Step : 40, LR : 9.375000000000001e-06, Avg Loss : 0.7826\n",
            "Epoch: 3, Step : 50, LR : 9.222560975609756e-06, Avg Loss : 0.8974\n",
            "Epoch: 3, Step : 60, LR : 9.070121951219513e-06, Avg Loss : 0.7840\n",
            "Epoch: 3, Step : 70, LR : 8.917682926829268e-06, Avg Loss : 0.8967\n",
            "Epoch: 3, Step : 80, LR : 8.765243902439025e-06, Avg Loss : 0.8185\n",
            "Epoch: 3, Step : 90, LR : 8.612804878048782e-06, Avg Loss : 0.8178\n",
            "Epoch: 3, Step : 100, LR : 8.460365853658538e-06, Avg Loss : 0.8604\n",
            "Epoch: 3, Step : 110, LR : 8.307926829268293e-06, Avg Loss : 0.9391\n",
            "Epoch: 3, Step : 120, LR : 8.15548780487805e-06, Avg Loss : 0.9251\n",
            "Epoch: 3, Step : 130, LR : 8.003048780487805e-06, Avg Loss : 0.7956\n",
            "Epoch: 3, Step : 140, LR : 7.850609756097562e-06, Avg Loss : 0.8300\n",
            "Epoch: 3, Step : 150, LR : 7.698170731707317e-06, Avg Loss : 0.9277\n",
            "Epoch: 3, Step : 160, LR : 7.545731707317074e-06, Avg Loss : 0.7741\n",
            "Epoch: 3, Step : 170, LR : 7.393292682926831e-06, Avg Loss : 0.8225\n",
            "Epoch: 3, Step : 180, LR : 7.240853658536586e-06, Avg Loss : 0.9253\n",
            "Epoch: 3, Step : 190, LR : 7.088414634146342e-06, Avg Loss : 0.9060\n",
            "Epoch: 3, Step : 200, LR : 6.935975609756098e-06, Avg Loss : 0.8253\n",
            "Epoch: 3, Step : 210, LR : 6.783536585365854e-06, Avg Loss : 0.8669\n",
            "Epoch: 3, Step : 220, LR : 6.63109756097561e-06, Avg Loss : 0.9274\n",
            "Epoch: 3, Step : 230, LR : 6.478658536585366e-06, Avg Loss : 0.8314\n",
            "Epoch: 3, Step : 240, LR : 6.326219512195122e-06, Avg Loss : 0.8674\n",
            "Epoch: 3, Step : 250, LR : 6.173780487804879e-06, Avg Loss : 0.7763\n",
            "Epoch: 3, Step : 260, LR : 6.021341463414635e-06, Avg Loss : 0.9323\n",
            "Epoch: 3, Step : 270, LR : 5.868902439024391e-06, Avg Loss : 0.8473\n",
            "Epoch: 3, Step : 280, LR : 5.716463414634147e-06, Avg Loss : 0.8237\n",
            "Epoch: 3, Step : 290, LR : 5.5640243902439025e-06, Avg Loss : 0.8078\n",
            "Epoch: 3, Step : 300, LR : 5.411585365853659e-06, Avg Loss : 0.7526\n",
            "Epoch: 3, Step : 310, LR : 5.259146341463415e-06, Avg Loss : 0.7562\n",
            "Epoch: 3, Step : 320, LR : 5.106707317073171e-06, Avg Loss : 0.7791\n",
            "Epoch 3 Total Mean Loss : 0.8467\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.9772 Valid Acc : 70.96\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 1\n",
            "Early stopping\n",
            "Train Completed. End Program.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "GFiQGULKrxfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load checkpoint"
      ],
      "metadata": {
        "id": "4aim45otF4si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = input()\n",
        "checkpoint = torch.load(f'./model_ckpt_{best_epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4StQ5rCRPJt",
        "outputId": "be0d0543-00fd-44f1-e78a-17bbd3f20662"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSy2twvbRSHd",
        "outputId": "92038ba9-2f0e-4b59-ca6c-97209c31ebfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOuSODA6RSQ9",
        "outputId": "740e836c-e715-435e-814c-aac89b3dd771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoxlaI_RSTb",
        "outputId": "a5ce07be-f11a-4461-92e3-d9e39aea8e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict and evaluate"
      ],
      "metadata": {
        "id": "w1uKfufLF8kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n"
      ],
      "metadata": {
        "id": "UhtXfy8kJvMR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "NQAuNkxRRdxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b648e50-dc6b-463b-a0dc-24a69e226845"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))"
      ],
      "metadata": {
        "id": "MjSIuizoaVg1"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from scipy.stats import pearsonr\n",
        "def evaluate(pred, test):\n",
        "    pred_binary = list(map(lambda x: 1 if x>=3 else 0, pred))\n",
        "    test_binary_label = list(map(lambda x: 1 if x>=3 else 0, test))\n",
        "    print(f'acc : {accuracy_score(test_binary_label, pred_binary)}')\n",
        "    print(f'f1 : {f1_score(test_binary_label, pred_binary)}')\n",
        "    print(f'pearson : {pearsonr(test, pred)}')\n",
        "    return f1_score(test_binary_label, pred_binary)\n",
        "    "
      ],
      "metadata": {
        "id": "r_CM_p_SzS3t"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv_HfFaARi6o",
        "outputId": "aff0cb65-5eb4-4bb2-d22e-54e2fe4f87bb"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.789980732177264\n",
            "f1 : 0.7583148558758315\n",
            "pearson : (0.7703758708885954, 4.033363147548586e-103)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7583148558758315"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save outputs"
      ],
      "metadata": {
        "id": "UwfT52-LGDrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame(labels,columns=['pred_real_label'])\n",
        "filename = input()\n",
        "output.to_csv(f'{filename}.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOiLVeOGFay",
        "outputId": "b1083e19-263f-487d-a6d4-4d644370f1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_pred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G7e_OlKR4qni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model weights"
      ],
      "metadata": {
        "id": "ODz2YVO45-MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bert_baseline(hidden_size=768, n_label=6)"
      ],
      "metadata": {
        "id": "nNiDZphx5FXK",
        "outputId": "0ee120c1-cc92-4a8d-ce9b-4f7772b7bb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "rG_D-WBV5kMU",
        "outputId": "4effe6e2-a9ea-46d8-ecf4-c442a3939ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))\n",
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "id": "vzg0kIpZ5z66",
        "outputId": "4961f688-3c8b-4f89-94fc-ac026e7fe063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.7533718689788054\n",
            "f1 : 0.7697841726618705\n",
            "pearson : (0.7789983354145806, 7.071859924703616e-107)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZDS8IJNaVyB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "C91sdB_P6Cym",
        "outputId": "a1792743-b609-4176-af1f-788d09947ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.3 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=564d77cf348a0cd5c7121989ff9d940a1265ce345096a710987aea97dc358e32\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 64\n",
        "epochs=4\n",
        "patience=1\n",
        "\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "customModel = Bert_baseline(hidden_size=768, n_label=6)"
      ],
      "metadata": {
        "id": "GiELJugZC85y",
        "outputId": "9e345fc2-c080-44f2-99e8-1090d1537d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):  # `trial` is an object passed by Optuna.\n",
        "\n",
        "    lr = trial.suggest_float(\"lr\",1e-5,1e-1,log=True)\n",
        "\n",
        "    customOptimizer = AdamW(\n",
        "        customModel.parameters(), # update 대상 파라미터를 입력\n",
        "        lr=lr,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset),\n",
        "        collate_fn = custom_collate_fn\n",
        "    )\n",
        "\n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size = eval_batch_size,\n",
        "        sampler = SequentialSampler(valid_dataset),\n",
        "        collate_fn = custom_collate_fn\n",
        "    )\n",
        "    model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)\n",
        "\n",
        "    \n",
        "    loss_list=[]\n",
        "    # train_dataloaer 학습을 epochs만큼 반복\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "        \n",
        "        # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "        total_loss, batch_loss, batch_count = 0,0,0\n",
        "    \n",
        "        # model을 train 모드로 설정 & device 할당\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "        \n",
        "        # data iterator를 돌면서 하나씩 학습\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_count+=1\n",
        "            \n",
        "            # tensor 연산 전, 각 tensor에 device 할당\n",
        "            batch = tuple(item.to(device) for item in batch)\n",
        "        \n",
        "            batch_input, batch_label = batch\n",
        "        \n",
        "            # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "            model.zero_grad()\n",
        "        \n",
        "            # forward\n",
        "            logits = model(**batch_input)\n",
        "        \n",
        "            # loss\n",
        "            loss = loss_fct(logits, batch_label)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "            # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "            loss.backward()\n",
        "            \n",
        "            # gradient clipping 적용 \n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            # optimizer & scheduler 업데이트\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "            if (step % 10 == 0 and step != 0):\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                # reset \n",
        "                batch_loss, batch_count = 0,0\n",
        "        \n",
        "        print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "        print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "        \n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "            print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "        loss_list.append(valid_loss)\n",
        "    \n",
        "    return min(loss_list)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100, timeout=600)  # Specify the number of trials. "
      ],
      "metadata": {
        "id": "jksNuvvL6C03",
        "outputId": "58d15799-3e7e-488a-eddd-6c00c1847ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-29 04:25:40,374]\u001b[0m A new study created in memory with name: no-name-7984f4d7-37b9-4ba9-a921-04dbb67db5c9\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total train steps with 4 epochs: 1312\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 1.774278655621045e-05, Avg Loss : 1.6451\n",
            "Epoch: 1, Step : 20, LR : 1.7606408488906756e-05, Avg Loss : 1.5946\n",
            "Epoch: 1, Step : 30, LR : 1.7470030421603063e-05, Avg Loss : 1.4826\n",
            "Epoch: 1, Step : 40, LR : 1.7333652354299372e-05, Avg Loss : 1.4404\n",
            "Epoch: 1, Step : 50, LR : 1.719727428699568e-05, Avg Loss : 1.3911\n",
            "Epoch: 1, Step : 60, LR : 1.7060896219691985e-05, Avg Loss : 1.2810\n",
            "Epoch: 1, Step : 70, LR : 1.6924518152388294e-05, Avg Loss : 1.2596\n",
            "Epoch: 1, Step : 80, LR : 1.6788140085084597e-05, Avg Loss : 1.3690\n",
            "Epoch: 1, Step : 90, LR : 1.6651762017780907e-05, Avg Loss : 1.2826\n",
            "Epoch: 1, Step : 100, LR : 1.6515383950477213e-05, Avg Loss : 1.1932\n",
            "Epoch: 1, Step : 110, LR : 1.637900588317352e-05, Avg Loss : 1.3056\n",
            "Epoch: 1, Step : 120, LR : 1.6242627815869826e-05, Avg Loss : 1.2231\n",
            "Epoch: 1, Step : 130, LR : 1.6106249748566135e-05, Avg Loss : 1.1162\n",
            "Epoch: 1, Step : 140, LR : 1.596987168126244e-05, Avg Loss : 1.1650\n",
            "Epoch: 1, Step : 150, LR : 1.5833493613958748e-05, Avg Loss : 1.1912\n",
            "Epoch: 1, Step : 160, LR : 1.5697115546655057e-05, Avg Loss : 1.1373\n",
            "Epoch: 1, Step : 170, LR : 1.5560737479351364e-05, Avg Loss : 1.0929\n",
            "Epoch: 1, Step : 180, LR : 1.542435941204767e-05, Avg Loss : 1.1161\n",
            "Epoch: 1, Step : 190, LR : 1.5287981344743976e-05, Avg Loss : 1.1794\n",
            "Epoch: 1, Step : 200, LR : 1.5151603277440284e-05, Avg Loss : 1.2166\n",
            "Epoch: 1, Step : 210, LR : 1.5015225210136592e-05, Avg Loss : 1.1675\n",
            "Epoch: 1, Step : 220, LR : 1.4878847142832898e-05, Avg Loss : 1.2021\n",
            "Epoch: 1, Step : 230, LR : 1.4742469075529206e-05, Avg Loss : 1.1123\n",
            "Epoch: 1, Step : 240, LR : 1.4606091008225513e-05, Avg Loss : 1.0442\n",
            "Epoch: 1, Step : 250, LR : 1.446971294092182e-05, Avg Loss : 1.0354\n",
            "Epoch: 1, Step : 260, LR : 1.4333334873618125e-05, Avg Loss : 1.1825\n",
            "Epoch: 1, Step : 270, LR : 1.4196956806314433e-05, Avg Loss : 1.1664\n",
            "Epoch: 1, Step : 280, LR : 1.406057873901074e-05, Avg Loss : 1.1846\n",
            "Epoch: 1, Step : 290, LR : 1.3924200671707047e-05, Avg Loss : 1.2666\n",
            "Epoch: 1, Step : 300, LR : 1.3787822604403355e-05, Avg Loss : 1.1541\n",
            "Epoch: 1, Step : 310, LR : 1.3651444537099661e-05, Avg Loss : 1.1104\n",
            "Epoch: 1, Step : 320, LR : 1.351506646979597e-05, Avg Loss : 1.0767\n",
            "Epoch 1 Total Mean Loss : 1.2285\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 1.0257 Valid Acc : 60.60\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 1.3269585948649321e-05, Avg Loss : 1.1358\n",
            "Epoch: 2, Step : 20, LR : 1.313320788134563e-05, Avg Loss : 1.0350\n",
            "Epoch: 2, Step : 30, LR : 1.2996829814041936e-05, Avg Loss : 1.0522\n",
            "Epoch: 2, Step : 40, LR : 1.2860451746738243e-05, Avg Loss : 1.1015\n",
            "Epoch: 2, Step : 50, LR : 1.2724073679434551e-05, Avg Loss : 1.0704\n",
            "Epoch: 2, Step : 60, LR : 1.2587695612130858e-05, Avg Loss : 1.0757\n",
            "Epoch: 2, Step : 70, LR : 1.2451317544827166e-05, Avg Loss : 1.1181\n",
            "Epoch: 2, Step : 80, LR : 1.231493947752347e-05, Avg Loss : 0.9917\n",
            "Epoch: 2, Step : 90, LR : 1.2178561410219778e-05, Avg Loss : 0.9981\n",
            "Epoch: 2, Step : 100, LR : 1.2042183342916084e-05, Avg Loss : 1.0008\n",
            "Epoch: 2, Step : 110, LR : 1.1905805275612392e-05, Avg Loss : 0.9209\n",
            "Epoch: 2, Step : 120, LR : 1.1769427208308699e-05, Avg Loss : 1.0293\n",
            "Epoch: 2, Step : 130, LR : 1.1633049141005007e-05, Avg Loss : 0.9058\n",
            "Epoch: 2, Step : 140, LR : 1.1496671073701314e-05, Avg Loss : 0.8854\n",
            "Epoch: 2, Step : 150, LR : 1.136029300639762e-05, Avg Loss : 1.0546\n",
            "Epoch: 2, Step : 160, LR : 1.1223914939093929e-05, Avg Loss : 1.0070\n",
            "Epoch: 2, Step : 170, LR : 1.1087536871790235e-05, Avg Loss : 0.9886\n",
            "Epoch: 2, Step : 180, LR : 1.0951158804486543e-05, Avg Loss : 0.8988\n",
            "Epoch: 2, Step : 190, LR : 1.0814780737182847e-05, Avg Loss : 0.9403\n",
            "Epoch: 2, Step : 200, LR : 1.0678402669879155e-05, Avg Loss : 0.8767\n",
            "Epoch: 2, Step : 210, LR : 1.0542024602575463e-05, Avg Loss : 1.0055\n",
            "Epoch: 2, Step : 220, LR : 1.040564653527177e-05, Avg Loss : 0.9100\n",
            "Epoch: 2, Step : 230, LR : 1.0269268467968077e-05, Avg Loss : 0.9296\n",
            "Epoch: 2, Step : 240, LR : 1.0132890400664384e-05, Avg Loss : 0.9574\n",
            "Epoch: 2, Step : 250, LR : 9.996512333360692e-06, Avg Loss : 0.9204\n",
            "Epoch: 2, Step : 260, LR : 9.860134266056998e-06, Avg Loss : 0.8745\n",
            "Epoch: 2, Step : 270, LR : 9.723756198753306e-06, Avg Loss : 0.9316\n",
            "Epoch: 2, Step : 280, LR : 9.587378131449612e-06, Avg Loss : 0.9103\n",
            "Epoch: 2, Step : 290, LR : 9.45100006414592e-06, Avg Loss : 0.8503\n",
            "Epoch: 2, Step : 300, LR : 9.314621996842228e-06, Avg Loss : 0.8950\n",
            "Epoch: 2, Step : 310, LR : 9.178243929538534e-06, Avg Loss : 0.8955\n",
            "Epoch: 2, Step : 320, LR : 9.041865862234842e-06, Avg Loss : 0.9406\n",
            "Epoch 2 Total Mean Loss : 0.9721\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.9024 Valid Acc : 74.31\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 8.796385341088194e-06, Avg Loss : 0.8106\n",
            "Epoch: 3, Step : 20, LR : 8.6600072737845e-06, Avg Loss : 0.8296\n",
            "Epoch: 3, Step : 30, LR : 8.523629206480808e-06, Avg Loss : 0.9073\n",
            "Epoch: 3, Step : 40, LR : 8.387251139177115e-06, Avg Loss : 0.7794\n",
            "Epoch: 3, Step : 50, LR : 8.250873071873423e-06, Avg Loss : 0.8234\n",
            "Epoch: 3, Step : 60, LR : 8.114495004569729e-06, Avg Loss : 0.8571\n",
            "Epoch: 3, Step : 70, LR : 7.978116937266035e-06, Avg Loss : 0.8760\n",
            "Epoch: 3, Step : 80, LR : 7.841738869962343e-06, Avg Loss : 0.8907\n",
            "Epoch: 3, Step : 90, LR : 7.705360802658651e-06, Avg Loss : 0.7691\n",
            "Epoch: 3, Step : 100, LR : 7.568982735354958e-06, Avg Loss : 0.8304\n",
            "Epoch: 3, Step : 110, LR : 7.432604668051264e-06, Avg Loss : 0.8831\n",
            "Epoch: 3, Step : 120, LR : 7.2962266007475714e-06, Avg Loss : 0.8300\n",
            "Epoch: 3, Step : 130, LR : 7.1598485334438785e-06, Avg Loss : 0.7924\n",
            "Epoch: 3, Step : 140, LR : 7.023470466140186e-06, Avg Loss : 0.9141\n",
            "Epoch: 3, Step : 150, LR : 6.887092398836493e-06, Avg Loss : 0.8813\n",
            "Epoch: 3, Step : 160, LR : 6.750714331532799e-06, Avg Loss : 0.8581\n",
            "Epoch: 3, Step : 170, LR : 6.614336264229107e-06, Avg Loss : 0.8679\n",
            "Epoch: 3, Step : 180, LR : 6.477958196925414e-06, Avg Loss : 0.8774\n",
            "Epoch: 3, Step : 190, LR : 6.341580129621721e-06, Avg Loss : 0.8934\n",
            "Epoch: 3, Step : 200, LR : 6.205202062318028e-06, Avg Loss : 0.7250\n",
            "Epoch: 3, Step : 210, LR : 6.068823995014335e-06, Avg Loss : 0.8108\n",
            "Epoch: 3, Step : 220, LR : 5.9324459277106424e-06, Avg Loss : 0.8627\n",
            "Epoch: 3, Step : 230, LR : 5.796067860406949e-06, Avg Loss : 0.9213\n",
            "Epoch: 3, Step : 240, LR : 5.659689793103256e-06, Avg Loss : 0.8384\n",
            "Epoch: 3, Step : 250, LR : 5.523311725799564e-06, Avg Loss : 0.7635\n",
            "Epoch: 3, Step : 260, LR : 5.386933658495871e-06, Avg Loss : 0.8853\n",
            "Epoch: 3, Step : 270, LR : 5.250555591192178e-06, Avg Loss : 0.8662\n",
            "Epoch: 3, Step : 280, LR : 5.114177523888485e-06, Avg Loss : 0.7747\n",
            "Epoch: 3, Step : 290, LR : 4.977799456584792e-06, Avg Loss : 0.8820\n",
            "Epoch: 3, Step : 300, LR : 4.841421389281098e-06, Avg Loss : 0.9121\n",
            "Epoch: 3, Step : 310, LR : 4.7050433219774055e-06, Avg Loss : 0.8671\n",
            "Epoch: 3, Step : 320, LR : 4.568665254673713e-06, Avg Loss : 0.8198\n",
            "Epoch 3 Total Mean Loss : 0.8453\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.8628 Valid Acc : 74.50\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "*****Epoch 4 Train Start*****\n",
            "Epoch: 4, Step : 10, LR : 4.323184733527065e-06, Avg Loss : 0.7511\n",
            "Epoch: 4, Step : 20, LR : 4.186806666223373e-06, Avg Loss : 0.8393\n",
            "Epoch: 4, Step : 30, LR : 4.05042859891968e-06, Avg Loss : 0.7524\n",
            "Epoch: 4, Step : 40, LR : 3.914050531615987e-06, Avg Loss : 0.7188\n",
            "Epoch: 4, Step : 50, LR : 3.7776724643122938e-06, Avg Loss : 0.7510\n",
            "Epoch: 4, Step : 60, LR : 3.641294397008601e-06, Avg Loss : 0.8346\n",
            "Epoch: 4, Step : 70, LR : 3.5049163297049084e-06, Avg Loss : 0.7918\n",
            "Epoch: 4, Step : 80, LR : 3.3685382624012155e-06, Avg Loss : 0.7542\n",
            "Epoch: 4, Step : 90, LR : 3.232160195097522e-06, Avg Loss : 0.8408\n",
            "Epoch: 4, Step : 100, LR : 3.0957821277938293e-06, Avg Loss : 0.8116\n",
            "Epoch: 4, Step : 110, LR : 2.9594040604901368e-06, Avg Loss : 0.7637\n",
            "Epoch: 4, Step : 120, LR : 2.8230259931864435e-06, Avg Loss : 0.8070\n",
            "Epoch: 4, Step : 130, LR : 2.6866479258827506e-06, Avg Loss : 0.6883\n",
            "Epoch: 4, Step : 140, LR : 2.5502698585790577e-06, Avg Loss : 0.7318\n",
            "Epoch: 4, Step : 150, LR : 2.4138917912753648e-06, Avg Loss : 0.7721\n",
            "Epoch: 4, Step : 160, LR : 2.277513723971672e-06, Avg Loss : 0.7323\n",
            "Epoch: 4, Step : 170, LR : 2.141135656667979e-06, Avg Loss : 0.8727\n",
            "Epoch: 4, Step : 180, LR : 2.004757589364286e-06, Avg Loss : 0.7835\n",
            "Epoch: 4, Step : 190, LR : 1.868379522060593e-06, Avg Loss : 0.7072\n",
            "Epoch: 4, Step : 200, LR : 1.7320014547569003e-06, Avg Loss : 0.8799\n",
            "Epoch: 4, Step : 210, LR : 1.5956233874532071e-06, Avg Loss : 0.7547\n",
            "Epoch: 4, Step : 220, LR : 1.4592453201495145e-06, Avg Loss : 0.7657\n",
            "Epoch: 4, Step : 230, LR : 1.3228672528458213e-06, Avg Loss : 0.7657\n",
            "Epoch: 4, Step : 240, LR : 1.1864891855421284e-06, Avg Loss : 0.8473\n",
            "Epoch: 4, Step : 250, LR : 1.0501111182384355e-06, Avg Loss : 0.7686\n",
            "Epoch: 4, Step : 260, LR : 9.137330509347425e-07, Avg Loss : 0.7894\n",
            "Epoch: 4, Step : 270, LR : 7.773549836310496e-07, Avg Loss : 0.7645\n",
            "Epoch: 4, Step : 280, LR : 6.409769163273567e-07, Avg Loss : 0.8231\n",
            "Epoch: 4, Step : 290, LR : 5.045988490236638e-07, Avg Loss : 0.8374\n",
            "Epoch: 4, Step : 300, LR : 3.6822078171997094e-07, Avg Loss : 0.6905\n",
            "Epoch: 4, Step : 310, LR : 2.3184271441627796e-07, Avg Loss : 0.8041\n",
            "Epoch: 4, Step : 320, LR : 9.546464711258506e-08, Avg Loss : 0.7736\n",
            "Epoch 4 Total Mean Loss : 0.7808\n",
            "*****Epoch 4 Train Finish*****\n",
            "\n",
            "*****Epoch 4 Valid Start*****\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-29 04:31:59,109]\u001b[0m Trial 0 finished with value: 0.8410858637408206 and parameters: {'lr': 1.7892802430244512e-05}. Best is trial 0 with value: 0.8410858637408206.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Valid Loss : 0.8411 Valid Acc : 75.90\n",
            "*****Epoch 4 Valid Finish*****\n",
            "\n",
            "Total train steps with 4 epochs: 1312\n",
            "*****Epoch 1 Train Start*****\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Step : 10, LR : 3.604445018440736e-05, Avg Loss : 0.8683\n",
            "Epoch: 1, Step : 20, LR : 3.576739829982314e-05, Avg Loss : 0.8408\n",
            "Epoch: 1, Step : 30, LR : 3.5490346415238916e-05, Avg Loss : 0.8120\n",
            "Epoch: 1, Step : 40, LR : 3.521329453065469e-05, Avg Loss : 0.8005\n",
            "Epoch: 1, Step : 50, LR : 3.493624264607047e-05, Avg Loss : 1.0246\n",
            "Epoch: 1, Step : 60, LR : 3.4659190761486246e-05, Avg Loss : 1.0004\n",
            "Epoch: 1, Step : 70, LR : 3.438213887690203e-05, Avg Loss : 0.8591\n",
            "Epoch: 1, Step : 80, LR : 3.41050869923178e-05, Avg Loss : 0.8949\n",
            "Epoch: 1, Step : 90, LR : 3.382803510773358e-05, Avg Loss : 0.8456\n",
            "Epoch: 1, Step : 100, LR : 3.355098322314936e-05, Avg Loss : 0.8637\n",
            "Epoch: 1, Step : 110, LR : 3.327393133856514e-05, Avg Loss : 0.8923\n",
            "Epoch: 1, Step : 120, LR : 3.299687945398091e-05, Avg Loss : 0.8833\n",
            "Epoch: 1, Step : 130, LR : 3.271982756939669e-05, Avg Loss : 0.8673\n",
            "Epoch: 1, Step : 140, LR : 3.244277568481247e-05, Avg Loss : 0.9596\n",
            "Epoch: 1, Step : 150, LR : 3.216572380022824e-05, Avg Loss : 0.8626\n",
            "Epoch: 1, Step : 160, LR : 3.1888671915644025e-05, Avg Loss : 0.8639\n",
            "Epoch: 1, Step : 170, LR : 3.16116200310598e-05, Avg Loss : 0.7920\n",
            "Epoch: 1, Step : 180, LR : 3.133456814647558e-05, Avg Loss : 0.7885\n",
            "Epoch: 1, Step : 190, LR : 3.1057516261891355e-05, Avg Loss : 0.8986\n",
            "Epoch: 1, Step : 200, LR : 3.078046437730713e-05, Avg Loss : 0.7824\n",
            "Epoch: 1, Step : 210, LR : 3.050341249272291e-05, Avg Loss : 0.7996\n",
            "Epoch: 1, Step : 220, LR : 3.0226360608138685e-05, Avg Loss : 0.8676\n",
            "Epoch: 1, Step : 230, LR : 2.9949308723554466e-05, Avg Loss : 0.8933\n",
            "Epoch: 1, Step : 240, LR : 2.967225683897024e-05, Avg Loss : 0.7354\n",
            "Epoch: 1, Step : 250, LR : 2.939520495438602e-05, Avg Loss : 0.8466\n",
            "Epoch: 1, Step : 260, LR : 2.9118153069801796e-05, Avg Loss : 0.9471\n",
            "Epoch: 1, Step : 270, LR : 2.8841101185217574e-05, Avg Loss : 0.7297\n",
            "Epoch: 1, Step : 280, LR : 2.856404930063335e-05, Avg Loss : 0.9878\n",
            "Epoch: 1, Step : 290, LR : 2.8286997416049127e-05, Avg Loss : 0.7386\n",
            "Epoch: 1, Step : 300, LR : 2.8009945531464908e-05, Avg Loss : 0.9034\n",
            "Epoch: 1, Step : 310, LR : 2.7732893646880682e-05, Avg Loss : 0.7762\n",
            "Epoch: 1, Step : 320, LR : 2.745584176229646e-05, Avg Loss : 0.8471\n",
            "Epoch 1 Total Mean Loss : 0.8590\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.9336 Valid Acc : 72.22\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 2.6957148370044857e-05, Avg Loss : 0.7282\n",
            "Epoch: 2, Step : 20, LR : 2.6680096485460638e-05, Avg Loss : 0.7616\n",
            "Epoch: 2, Step : 30, LR : 2.6403044600876413e-05, Avg Loss : 0.6718\n",
            "Epoch: 2, Step : 40, LR : 2.612599271629219e-05, Avg Loss : 0.6863\n",
            "Epoch: 2, Step : 50, LR : 2.584894083170797e-05, Avg Loss : 0.6570\n",
            "Epoch: 2, Step : 60, LR : 2.5571888947123746e-05, Avg Loss : 0.7324\n",
            "Epoch: 2, Step : 70, LR : 2.5294837062539524e-05, Avg Loss : 0.7369\n",
            "Epoch: 2, Step : 80, LR : 2.5017785177955302e-05, Avg Loss : 0.7600\n",
            "Epoch: 2, Step : 90, LR : 2.474073329337108e-05, Avg Loss : 0.7513\n",
            "Epoch: 2, Step : 100, LR : 2.4463681408786854e-05, Avg Loss : 0.7451\n",
            "Epoch: 2, Step : 110, LR : 2.4186629524202635e-05, Avg Loss : 0.6562\n",
            "Epoch: 2, Step : 120, LR : 2.390957763961841e-05, Avg Loss : 0.7974\n",
            "Epoch: 2, Step : 130, LR : 2.3632525755034188e-05, Avg Loss : 0.7690\n",
            "Epoch: 2, Step : 140, LR : 2.335547387044997e-05, Avg Loss : 0.7358\n",
            "Epoch: 2, Step : 150, LR : 2.3078421985865743e-05, Avg Loss : 0.7985\n",
            "Epoch: 2, Step : 160, LR : 2.280137010128152e-05, Avg Loss : 0.6548\n",
            "Epoch: 2, Step : 170, LR : 2.2524318216697296e-05, Avg Loss : 0.8088\n",
            "Epoch: 2, Step : 180, LR : 2.2247266332113077e-05, Avg Loss : 0.7422\n",
            "Epoch: 2, Step : 190, LR : 2.197021444752885e-05, Avg Loss : 0.7972\n",
            "Epoch: 2, Step : 200, LR : 2.169316256294463e-05, Avg Loss : 0.6826\n",
            "Epoch: 2, Step : 210, LR : 2.141611067836041e-05, Avg Loss : 0.6537\n",
            "Epoch: 2, Step : 220, LR : 2.1139058793776185e-05, Avg Loss : 0.7778\n",
            "Epoch: 2, Step : 230, LR : 2.0862006909191963e-05, Avg Loss : 0.6544\n",
            "Epoch: 2, Step : 240, LR : 2.0584955024607737e-05, Avg Loss : 0.6365\n",
            "Epoch: 2, Step : 250, LR : 2.030790314002352e-05, Avg Loss : 0.6869\n",
            "Epoch: 2, Step : 260, LR : 2.0030851255439293e-05, Avg Loss : 0.6999\n",
            "Epoch: 2, Step : 270, LR : 1.975379937085507e-05, Avg Loss : 0.6791\n",
            "Epoch: 2, Step : 280, LR : 1.947674748627085e-05, Avg Loss : 0.7298\n",
            "Epoch: 2, Step : 290, LR : 1.9199695601686627e-05, Avg Loss : 0.7941\n",
            "Epoch: 2, Step : 300, LR : 1.8922643717102405e-05, Avg Loss : 0.6283\n",
            "Epoch: 2, Step : 310, LR : 1.8645591832518182e-05, Avg Loss : 0.7037\n",
            "Epoch: 2, Step : 320, LR : 1.836853994793396e-05, Avg Loss : 0.7724\n",
            "Epoch 2 Total Mean Loss : 0.7219\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.8348 Valid Acc : 73.49\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 1.786984655568236e-05, Avg Loss : 0.6046\n",
            "Epoch: 3, Step : 20, LR : 1.7592794671098135e-05, Avg Loss : 0.6598\n",
            "Epoch: 3, Step : 30, LR : 1.7315742786513913e-05, Avg Loss : 0.6129\n",
            "Epoch: 3, Step : 40, LR : 1.703869090192969e-05, Avg Loss : 0.7369\n",
            "Epoch: 3, Step : 50, LR : 1.676163901734547e-05, Avg Loss : 0.6668\n",
            "Epoch: 3, Step : 60, LR : 1.6484587132761246e-05, Avg Loss : 0.6187\n",
            "Epoch: 3, Step : 70, LR : 1.620753524817702e-05, Avg Loss : 0.6398\n",
            "Epoch: 3, Step : 80, LR : 1.59304833635928e-05, Avg Loss : 0.6451\n",
            "Epoch: 3, Step : 90, LR : 1.5653431479008576e-05, Avg Loss : 0.6819\n",
            "Epoch: 3, Step : 100, LR : 1.5376379594424354e-05, Avg Loss : 0.6483\n",
            "Epoch: 3, Step : 110, LR : 1.5099327709840132e-05, Avg Loss : 0.6529\n",
            "Epoch: 3, Step : 120, LR : 1.482227582525591e-05, Avg Loss : 0.5931\n",
            "Epoch: 3, Step : 130, LR : 1.4545223940671686e-05, Avg Loss : 0.5983\n",
            "Epoch: 3, Step : 140, LR : 1.4268172056087464e-05, Avg Loss : 0.5774\n",
            "Epoch: 3, Step : 150, LR : 1.399112017150324e-05, Avg Loss : 0.6291\n",
            "Epoch: 3, Step : 160, LR : 1.3714068286919018e-05, Avg Loss : 0.5583\n",
            "Epoch: 3, Step : 170, LR : 1.3437016402334798e-05, Avg Loss : 0.6203\n",
            "Epoch: 3, Step : 180, LR : 1.3159964517750574e-05, Avg Loss : 0.6361\n",
            "Epoch: 3, Step : 190, LR : 1.2882912633166352e-05, Avg Loss : 0.7048\n",
            "Epoch: 3, Step : 200, LR : 1.260586074858213e-05, Avg Loss : 0.5565\n",
            "Epoch: 3, Step : 210, LR : 1.2328808863997906e-05, Avg Loss : 0.5380\n",
            "Epoch: 3, Step : 220, LR : 1.2051756979413684e-05, Avg Loss : 0.5319\n",
            "Epoch: 3, Step : 230, LR : 1.177470509482946e-05, Avg Loss : 0.5779\n",
            "Epoch: 3, Step : 240, LR : 1.1497653210245238e-05, Avg Loss : 0.5300\n",
            "Epoch: 3, Step : 250, LR : 1.1220601325661017e-05, Avg Loss : 0.5414\n",
            "Epoch: 3, Step : 260, LR : 1.0943549441076793e-05, Avg Loss : 0.6316\n",
            "Epoch: 3, Step : 270, LR : 1.0666497556492571e-05, Avg Loss : 0.5788\n",
            "Epoch: 3, Step : 280, LR : 1.0389445671908347e-05, Avg Loss : 0.5401\n",
            "Epoch: 3, Step : 290, LR : 1.0112393787324125e-05, Avg Loss : 0.6638\n",
            "Epoch: 3, Step : 300, LR : 9.835341902739903e-06, Avg Loss : 0.6538\n",
            "Epoch: 3, Step : 310, LR : 9.55829001815568e-06, Avg Loss : 0.5964\n",
            "Epoch: 3, Step : 320, LR : 9.281238133571457e-06, Avg Loss : 0.5986\n",
            "Epoch 3 Total Mean Loss : 0.6133\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.9209 Valid Acc : 74.01\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "*****Epoch 4 Train Start*****\n",
            "Epoch: 4, Step : 10, LR : 8.782544741319857e-06, Avg Loss : 0.5419\n",
            "Epoch: 4, Step : 20, LR : 8.505492856735635e-06, Avg Loss : 0.5314\n",
            "Epoch: 4, Step : 30, LR : 8.228440972151411e-06, Avg Loss : 0.5338\n",
            "Epoch: 4, Step : 40, LR : 7.951389087567189e-06, Avg Loss : 0.4438\n",
            "Epoch: 4, Step : 50, LR : 7.674337202982965e-06, Avg Loss : 0.5346\n",
            "Epoch: 4, Step : 60, LR : 7.397285318398743e-06, Avg Loss : 0.5377\n",
            "Epoch: 4, Step : 70, LR : 7.120233433814521e-06, Avg Loss : 0.5760\n",
            "Epoch: 4, Step : 80, LR : 6.843181549230299e-06, Avg Loss : 0.5301\n",
            "Epoch: 4, Step : 90, LR : 6.566129664646076e-06, Avg Loss : 0.5673\n",
            "Epoch: 4, Step : 100, LR : 6.289077780061853e-06, Avg Loss : 0.4793\n",
            "Epoch: 4, Step : 110, LR : 6.012025895477631e-06, Avg Loss : 0.4475\n",
            "Epoch: 4, Step : 120, LR : 5.734974010893408e-06, Avg Loss : 0.5061\n",
            "Epoch: 4, Step : 130, LR : 5.4579221263091855e-06, Avg Loss : 0.4994\n",
            "Epoch: 4, Step : 140, LR : 5.1808702417249625e-06, Avg Loss : 0.5530\n",
            "Epoch: 4, Step : 150, LR : 4.90381835714074e-06, Avg Loss : 0.5287\n",
            "Epoch: 4, Step : 160, LR : 4.626766472556517e-06, Avg Loss : 0.5578\n",
            "Epoch: 4, Step : 170, LR : 4.349714587972294e-06, Avg Loss : 0.5505\n",
            "Epoch: 4, Step : 180, LR : 4.072662703388072e-06, Avg Loss : 0.5421\n",
            "Epoch: 4, Step : 190, LR : 3.7956108188038497e-06, Avg Loss : 0.4527\n",
            "Epoch: 4, Step : 200, LR : 3.518558934219627e-06, Avg Loss : 0.5111\n",
            "Epoch: 4, Step : 210, LR : 3.241507049635404e-06, Avg Loss : 0.5226\n",
            "Epoch: 4, Step : 220, LR : 2.964455165051182e-06, Avg Loss : 0.4914\n",
            "Epoch: 4, Step : 230, LR : 2.687403280466959e-06, Avg Loss : 0.4923\n",
            "Epoch: 4, Step : 240, LR : 2.410351395882737e-06, Avg Loss : 0.5351\n",
            "Epoch: 4, Step : 250, LR : 2.133299511298514e-06, Avg Loss : 0.4576\n",
            "Epoch: 4, Step : 260, LR : 1.8562476267142913e-06, Avg Loss : 0.4633\n",
            "Epoch: 4, Step : 270, LR : 1.5791957421300688e-06, Avg Loss : 0.5548\n",
            "Epoch: 4, Step : 280, LR : 1.3021438575458462e-06, Avg Loss : 0.5321\n",
            "Epoch: 4, Step : 290, LR : 1.0250919729616236e-06, Avg Loss : 0.5817\n",
            "Epoch: 4, Step : 300, LR : 7.480400883774011e-07, Avg Loss : 0.5189\n",
            "Epoch: 4, Step : 310, LR : 4.709882037931784e-07, Avg Loss : 0.5442\n",
            "Epoch: 4, Step : 320, LR : 1.9393631920895584e-07, Avg Loss : 0.5507\n",
            "Epoch 4 Total Mean Loss : 0.5215\n",
            "*****Epoch 4 Train Finish*****\n",
            "\n",
            "*****Epoch 4 Valid Start*****\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-05-29 04:38:17,702]\u001b[0m Trial 1 finished with value: 0.8348305821418762 and parameters: {'lr': 3.6349207257450006e-05}. Best is trial 1 with value: 0.8348305821418762.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Valid Loss : 0.9668 Valid Acc : 74.67\n",
            "*****Epoch 4 Valid Finish*****\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Minimum objective value: ' + str(study.best_value))\n",
        "print('Best parameter: ' + str(study.best_params))"
      ],
      "metadata": {
        "id": "QarUZ2Vm6C3c",
        "outputId": "cfc127c4-e0fb-4cc2-f841-ee5e9109eac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum objective value: 0.8348305821418762\n",
            "Best parameter: {'lr': 3.6349207257450006e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KuKNaaDS6C56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rEJG0u5t6C8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IdPtw6jG6C-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}