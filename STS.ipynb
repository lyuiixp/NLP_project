{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5pU2GW5lT9hExG6aIoPk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a27af7aba6be49f68dc80ef5316d344f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b559b821d974a3eab35b2b727e108c2",
              "IPY_MODEL_673c95a050bf41f99b43557d93013dc3",
              "IPY_MODEL_c4e833bd4d9341b7ba3fcac0cdf8e80f"
            ],
            "layout": "IPY_MODEL_422b63e970d14f46b0a14f93b490f736"
          }
        },
        "1b559b821d974a3eab35b2b727e108c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78531c50db84b4281a619947d762907",
            "placeholder": "​",
            "style": "IPY_MODEL_878f75d8e2f54bd18d45d0045057bc43",
            "value": "Downloading: 100%"
          }
        },
        "673c95a050bf41f99b43557d93013dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5223d4e483884a5796c3bc14c7a9dfd8",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6383341f55754877982549b7f530bb0f",
            "value": 481
          }
        },
        "c4e833bd4d9341b7ba3fcac0cdf8e80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11bec32124fd4ba181967be1c4106b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_26de0f5a9aba42378f6358456fe1d2f0",
            "value": " 481/481 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "422b63e970d14f46b0a14f93b490f736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78531c50db84b4281a619947d762907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878f75d8e2f54bd18d45d0045057bc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5223d4e483884a5796c3bc14c7a9dfd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6383341f55754877982549b7f530bb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11bec32124fd4ba181967be1c4106b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26de0f5a9aba42378f6358456fe1d2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "777634d3b25e48328c90c4676180f730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1caadf479133427c82acc2849626ee83",
              "IPY_MODEL_e9454a3d017543f6ac566465f3493e6f",
              "IPY_MODEL_d7e9944754944e30a36178adc6002730"
            ],
            "layout": "IPY_MODEL_a9e8b9362c8946b1a6d8a68218db84be"
          }
        },
        "1caadf479133427c82acc2849626ee83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5233233b5b4a57a708175e7b11ec4f",
            "placeholder": "​",
            "style": "IPY_MODEL_009bd04b20a3483685b1c1ca07a26081",
            "value": "Downloading: 100%"
          }
        },
        "e9454a3d017543f6ac566465f3493e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4707c5b470547c38a4113d0204bdbb2",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee9a528be354d9e9d20f56855d9069c",
            "value": 501200538
          }
        },
        "d7e9944754944e30a36178adc6002730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_524b8fca03f94ca88aaa50769e691e54",
            "placeholder": "​",
            "style": "IPY_MODEL_141b8cf7cfbf4381bfa8e2b0c3b6e3d5",
            "value": " 478M/478M [00:11&lt;00:00, 49.5MB/s]"
          }
        },
        "a9e8b9362c8946b1a6d8a68218db84be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5233233b5b4a57a708175e7b11ec4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009bd04b20a3483685b1c1ca07a26081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4707c5b470547c38a4113d0204bdbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee9a528be354d9e9d20f56855d9069c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "524b8fca03f94ca88aaa50769e691e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141b8cf7cfbf4381bfa8e2b0c3b6e3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/NLP_project/blob/RoBERTa%2Fbaseline/STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n",
        "\n",
        "### BASELINE : RoBERTa\n",
        "\n",
        "#### 진행 사항\n",
        "1. 전처리 진행\n",
        "  - 중복행 삭제\n",
        "  - 문장검사\n",
        "\n",
        "2. 모델 정리 및 오류 수정\n",
        "  - 현재 오류 : 메모리....오류...\n",
        "\n",
        "3. 하이퍼 파라미터 튜닝 및 성능 향상\n",
        "  - 파라미터 사용 정보\n",
        "\n",
        "```python\n",
        "    # argument setting\n",
        "    task = \"sts\"\n",
        "    model_checkpoint = \"roberta-base\" \n",
        "    train_batch_size = 32\n",
        "    eval_batch_size = 64\n",
        "    epochs=4\n",
        "    patience=1\n",
        "    loss_fct = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW\n",
        "    # 실험용 epoch=1\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3qfGz4Pa-Whu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "6R8hyvUu-1sK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sw7ilyV-KU8",
        "outputId": "bdc499da-e02f-4f24-c5b6-536ad57038a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,  RandomSampler, SequentialSampler, random_split\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "kpKhz3Xi_A2j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZepTYxNV_QPi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJA6wul9_SI3",
        "outputId": "1ed78fd4-1e4b-40be-ef5c-296708c5edb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla T4\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data upload"
      ],
      "metadata": {
        "id": "yKpuYKgO_iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmKwlaCj_o-U",
        "outputId": "6dc55573-2ced-490d-b7b5-a0422e7edc79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/AIBootCamp/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUVn2-x__z2z",
        "outputId": "2964a75f-9e23-4192-9a4d-de68b050fc47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIBootCamp/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"data/klue-sts-v1.1\")\n",
        "print(f\"My data directory : {_DATA_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5otTsnqV_6DY",
        "outputId": "ddaa32e6-f6d7-48c4-efa7-50ee143bad69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/AIBootCamp/NLP\n",
            "My data directory : /content/drive/MyDrive/AIBootCamp/NLP/data/klue-sts-v1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 내 json 불러오기\n",
        "train_all = pd.read_json('./data/klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "test = pd.read_json('./data/klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "XEnQbro_AFC3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape\n",
        "train_all.shape, test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4t-v3-EAdKr",
        "outputId": "2c1c6e9b-73e5-4393-8a72-a2ed396c374f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11668, 6), (519, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "OkjYey9KAmwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 미리 검사"
      ],
      "metadata": {
        "id": "mcNuklZsRJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 확인\n",
        "train_all[train_all.duplicated(['sentence1', 'sentence2'],keep=False)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "guQfrCyKAtxP",
        "outputId": "de408ed2-7441-42fc-8508-3ea8f7678dfd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          guid      source  \\\n",
              "1514   klue-sts-v1_train_01514  policy-rtt   \n",
              "1661   klue-sts-v1_train_01661  airbnb-rtt   \n",
              "1715   klue-sts-v1_train_01715  airbnb-rtt   \n",
              "3872   klue-sts-v1_train_03872  policy-rtt   \n",
              "5139   klue-sts-v1_train_05139  policy-rtt   \n",
              "5292   klue-sts-v1_train_05292  policy-rtt   \n",
              "7045   klue-sts-v1_train_07045  policy-rtt   \n",
              "10908  klue-sts-v1_train_10908  policy-rtt   \n",
              "10939  klue-sts-v1_train_10939  policy-rtt   \n",
              "11112  klue-sts-v1_train_11112  policy-rtt   \n",
              "\n",
              "                                               sentence1  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "1661                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "1715                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "5139   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "7045   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10908  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10939  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "\n",
              "                                               sentence2  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "1661                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "1715                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "5139   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "7045   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10908  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10939  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "\n",
              "                                                  labels  \\\n",
              "1514   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "1661   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "1715   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "3872   {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "5139   {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "5292   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "7045   {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10908  {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10939  {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "11112  {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "\n",
              "                                             annotations  \n",
              "1514   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "1661   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "1715   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "3872   {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  \n",
              "5139   {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "5292   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "7045   {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10908  {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10939  {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "11112  {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-419e2906-2098-4dcf-9242-875529f39a1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>klue-sts-v1_train_01514</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>klue-sts-v1_train_01661</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>klue-sts-v1_train_01715</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>klue-sts-v1_train_03872</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5139</th>\n",
              "      <td>klue-sts-v1_train_05139</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5292</th>\n",
              "      <td>klue-sts-v1_train_05292</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7045</th>\n",
              "      <td>klue-sts-v1_train_07045</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10908</th>\n",
              "      <td>klue-sts-v1_train_10908</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10939</th>\n",
              "      <td>klue-sts-v1_train_10939</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11112</th>\n",
              "      <td>klue-sts-v1_train_11112</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-419e2906-2098-4dcf-9242-875529f39a1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-419e2906-2098-4dcf-9242-875529f39a1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-419e2906-2098-4dcf-9242-875529f39a1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 삭제\n",
        "train_all = train_all.drop_duplicates(['sentence1', 'sentence2'],keep=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Ux3Z7hBTBN-C"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null 값 확인\n",
        "train_all.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WExlyQx4DiPe",
        "outputId": "ae33ebb1-675b-41a6-edf7-37a0b987e784"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "guid           0\n",
              "source         0\n",
              "sentence1      0\n",
              "sentence2      0\n",
              "labels         0\n",
              "annotations    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모듈화"
      ],
      "metadata": {
        "id": "qkeEjBGuRNlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    def __init__(self,train,test):\n",
        "        self.train=train\n",
        "        self.test=test\n",
        "\n",
        "    def check_st(self, text):\n",
        "      text = re.sub('a-zA-Z一-龥㐀-䶵豈-龎[-=+,#/\\?:^$.@*\\\"※~&%ㆍ·!』\\\\‘〈〉|\\(\\)\\[\\]\\<\\>`\\'…》《]','', text)\n",
        "      return text\n",
        "    \n",
        "    def make_input(self,dataset):\n",
        "      '''\n",
        "      transform to the Input example\n",
        "      '''\n",
        "      #중복 제거\n",
        "      dataset = dataset.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "\n",
        "      sent_pairs = [sent1+' '+sent2 for sent1, sent2 in zip(dataset['sentence1'], dataset['sentence2'])]\n",
        "      sent_pairs = list(map(self.check_st, sent_pairs))\n",
        "\n",
        "      #real-label -> regression 활용 가능?\n",
        "      r_score=[i['real-label'] for i in dataset['labels']]\n",
        "\n",
        "      #custom label : int\n",
        "      c_score=[round(i['real-label']) for i in dataset['labels']]\n",
        "\n",
        "      #b_score label : [0,1] -> f1 scroe\n",
        "      b_score = [i['binary-label'] for i in dataset['labels']]\n",
        "      input_examples = pd.DataFrame({'guid': dataset['guid'], 'sent_pair' : sent_pairs, 'r_label' : r_score, 'c_label' : c_score, 'b_label' : b_score})\n",
        "\n",
        "      return input_examples"
      ],
      "metadata": {
        "id": "S3DhPvm6DrD_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp=Preprocess(train_all,test)"
      ],
      "metadata": {
        "id": "LZiy_8svGwLF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pp.make_input(train_all)\n",
        "test = pp.make_input(test)"
      ],
      "metadata": {
        "id": "0ye9SWKnI3O7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "fqDdE5qFSYba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이 라벨을 사용하려면 Data Agument가 필요할듯!!"
      ],
      "metadata": {
        "id": "-Q5gSkK2SuId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['c_label'].value_counts().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "NUTr4gFRRVkn",
        "outputId": "fde95a5a-d818-42be-c774-8be6576c6004"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1392a42390>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['b_label'].value_counts().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "9L49pm8USgcp",
        "outputId": "880ee10b-379f-4213-ce78-a58f1ecc3c44"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1392caad50>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAO+ElEQVR4nO3dcazdZX3H8fdHKm7TxRa5a1hbVhK7GfxDJTeAcVk2m7UFl5U/lGCWcUOa9J+6aLJkVv9pBpLgP2OSTJJGuhXjRMJmaByR3VTNsixAL4OhgKx3KGsboFdb2BxRB373x33qjvXe3nPh9Fzs834lJ+f5fZ/n9zvPL7n5nF9+5znnpqqQJPXhDSs9AUnS+Bj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdWbXSEziTCy+8sDZu3LjS05CkXygPP/zw96pqYqG+13Xob9y4kZmZmZWehiT9QknyzGJ93t6RpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjQ4V+ktVJ7kny7SRPJnlvkguSTCc53J7XtLFJcluS2SSPJbls4DhTbfzhJFNn66QkSQsb9stZnwG+WlUfTHI+8CvAJ4GDVXVLkt3AbuDjwFXApva4ArgduCLJBcAeYBIo4OEkB6rq5EjPaAVs3P0PKz2Fc8p3b/nASk9BOmcteaWf5K3A7wB3AFTVj6vqBWA7sL8N2w9c09rbgTtr3gPA6iQXAVuB6ao60YJ+Gtg20rORJJ3RMLd3LgHmgL9O8kiSzyV5M7C2qp5tY54D1rb2OuDIwP5HW22xuiRpTIYJ/VXAZcDtVfUe4H+Yv5XzUzX/j3ZH8s92k+xMMpNkZm5ubhSHlCQ1w4T+UeBoVT3Ytu9h/k3g+XbbhvZ8vPUfAzYM7L++1Rar/4yq2ltVk1U1OTGx4I/ESZJepSVDv6qeA44k+a1W2gw8ARwATq3AmQLube0DwPVtFc+VwIvtNtD9wJYka9pKny2tJkkak2FX7/wJ8IW2cudp4Abm3zDuTrIDeAa4to29D7gamAVeamOpqhNJbgIOtXE3VtWJkZyFJGkoQ4V+VT3K/FLL021eYGwBuxY5zj5g33ImKEkaHb+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIsN/IlfQLyv/3MDrnwv968Epfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRoUI/yXeTfDPJo0lmWu2CJNNJDrfnNa2eJLclmU3yWJLLBo4z1cYfTjJ1dk5JkrSY5Vzp/15VvbuqJtv2buBgVW0CDrZtgKuATe2xE7gd5t8kgD3AFcDlwJ5TbxSSpPF4Lbd3tgP7W3s/cM1A/c6a9wCwOslFwFZguqpOVNVJYBrY9hpeX5K0TMOGfgH/mOThJDtbbW1VPdvazwFrW3sdcGRg36OttlhdkjQmw/5j9N+uqmNJfg2YTvLtwc6qqiQ1igm1N5WdABdffPEoDilJaoa60q+qY+35OPBl5u/JP99u29Cej7fhx4ANA7uvb7XF6qe/1t6qmqyqyYmJieWdjSTpjJYM/SRvTvKrp9rAFuBbwAHg1AqcKeDe1j4AXN9W8VwJvNhuA90PbEmypn2Au6XVJEljMsztnbXAl5OcGv+3VfXVJIeAu5PsAJ4Brm3j7wOuBmaBl4AbAKrqRJKbgENt3I1VdWJkZyJJWtKSoV9VTwPvWqD+fWDzAvUCdi1yrH3AvuVPU5I0Cn4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MnToJzkvySNJvtK2L0nyYJLZJF9Kcn6rv6ltz7b+jQPH+ESrP5Vk66hPRpJ0Zsu50v8o8OTA9qeBW6vq7cBJYEer7wBOtvqtbRxJLgWuA94JbAM+m+S81zZ9SdJyDBX6SdYDHwA+17YDvB+4pw3ZD1zT2tvbNq1/cxu/Hbirqn5UVd8BZoHLR3ESkqThDHul/5fAnwE/adtvA16oqpfb9lFgXWuvA44AtP4X2/if1hfYR5I0BkuGfpI/AI5X1cNjmA9JdiaZSTIzNzc3jpeUpG4Mc6X/PuAPk3wXuIv52zqfAVYnWdXGrAeOtfYxYANA638r8P3B+gL7/FRV7a2qyaqanJiYWPYJSZIWt2ToV9Unqmp9VW1k/oPYr1XVHwFfBz7Yhk0B97b2gbZN6/9aVVWrX9dW91wCbAIeGtmZSJKWtGrpIYv6OHBXkk8BjwB3tPodwOeTzAInmH+joKoeT3I38ATwMrCrql55Da8vSVqmZYV+VX0D+EZrP80Cq2+q6ofAhxbZ/2bg5uVOUpI0Gn4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smToJ/mlJA8l+bckjyf581a/JMmDSWaTfCnJ+a3+prY92/o3DhzrE63+VJKtZ+ukJEkLG+ZK/0fA+6vqXcC7gW1JrgQ+DdxaVW8HTgI72vgdwMlWv7WNI8mlwHXAO4FtwGeTnDfKk5EkndmSoV/zftA239geBbwfuKfV9wPXtPb2tk3r35wkrX5XVf2oqr4DzAKXj+QsJElDGeqefpLzkjwKHAemgf8AXqiql9uQo8C61l4HHAFo/S8CbxusL7CPJGkMhgr9qnqlqt4NrGf+6vwdZ2tCSXYmmUkyMzc3d7ZeRpK6tKzVO1X1AvB14L3A6iSrWtd64FhrHwM2ALT+twLfH6wvsM/ga+ytqsmqmpyYmFjO9CRJSxhm9c5EktWt/cvA7wNPMh/+H2zDpoB7W/tA26b1f62qqtWva6t7LgE2AQ+N6kQkSUtbtfQQLgL2t5U2bwDurqqvJHkCuCvJp4BHgDva+DuAzyeZBU4wv2KHqno8yd3AE8DLwK6qemW0pyNJOpMlQ7+qHgPes0D9aRZYfVNVPwQ+tMixbgZuXv40JUmj4DdyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjS4Z+kg1Jvp7kiSSPJ/loq1+QZDrJ4fa8ptWT5LYks0keS3LZwLGm2vjDSabO3mlJkhYyzJX+y8CfVtWlwJXAriSXAruBg1W1CTjYtgGuAja1x07gdph/kwD2AFcAlwN7Tr1RSJLGY8nQr6pnq+pfW/u/gSeBdcB2YH8bth+4prW3A3fWvAeA1UkuArYC01V1oqpOAtPAtpGejSTpjJZ1Tz/JRuA9wIPA2qp6tnU9B6xt7XXAkYHdjrbaYnVJ0pgMHfpJ3gL8HfCxqvqvwb6qKqBGMaEkO5PMJJmZm5sbxSElSc1QoZ/kjcwH/heq6u9b+fl224b2fLzVjwEbBnZf32qL1X9GVe2tqsmqmpyYmFjOuUiSljDM6p0AdwBPVtVfDHQdAE6twJkC7h2oX99W8VwJvNhuA90PbEmypn2Au6XVJEljsmqIMe8D/hj4ZpJHW+2TwC3A3Ul2AM8A17a++4CrgVngJeAGgKo6keQm4FAbd2NVnRjJWUiShrJk6FfVPwNZpHvzAuML2LXIsfYB+5YzQUnS6PiNXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZMvST7EtyPMm3BmoXJJlOcrg9r2n1JLktyWySx5JcNrDPVBt/OMnU2TkdSdKZDHOl/zfAttNqu4GDVbUJONi2Aa4CNrXHTuB2mH+TAPYAVwCXA3tOvVFIksZnydCvqn8CTpxW3g7sb+39wDUD9Ttr3gPA6iQXAVuB6ao6UVUngWl+/o1EknSWvdp7+mur6tnWfg5Y29rrgCMD44622mL1n5NkZ5KZJDNzc3OvcnqSpIW85g9yq6qAGsFcTh1vb1VNVtXkxMTEqA4rSeLVh/7z7bYN7fl4qx8DNgyMW99qi9UlSWP0akP/AHBqBc4UcO9A/fq2iudK4MV2G+h+YEuSNe0D3C2tJkkao1VLDUjyReB3gQuTHGV+Fc4twN1JdgDPANe24fcBVwOzwEvADQBVdSLJTcChNu7Gqjr9w2FJ0lm2ZOhX1YcX6dq8wNgCdi1ynH3AvmXNTpI0Un4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MvbQT7ItyVNJZpPsHvfrS1LPxhr6Sc4D/gq4CrgU+HCSS8c5B0nq2biv9C8HZqvq6ar6MXAXsH3Mc5Ckbq0a8+utA44MbB8FrhgckGQnsLNt/iDJU2OaWw8uBL630pNYSj690jPQCvBvc7R+Y7GOcYf+kqpqL7B3pedxLkoyU1WTKz0P6XT+bY7PuG/vHAM2DGyvbzVJ0hiMO/QPAZuSXJLkfOA64MCY5yBJ3Rrr7Z2qejnJR4D7gfOAfVX1+Djn0Dlvm+n1yr/NMUlVrfQcJElj4jdyJakjhr4kdcTQl6SOvO7W6Wt0kryD+W88r2ulY8CBqnpy5WYlaSV5pX+OSvJx5n/mIsBD7RHgi/7QnV7Pktyw0nM4l7l65xyV5N+Bd1bV/55WPx94vKo2rczMpDNL8p9VdfFKz+Nc5e2dc9dPgF8HnjmtflHrk1ZMkscW6wLWjnMuvTH0z10fAw4mOcz//8jdxcDbgY+s2KykeWuBrcDJ0+oB/mX80+mHoX+OqqqvJvlN5n/OevCD3ENV9crKzUwC4CvAW6rq0dM7knxj/NPph/f0Jakjrt6RpI4Y+pLUEUNfkjpi6EtSRwx9SerI/wGQ2uEX/dDjPAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set"
      ],
      "metadata": {
        "id": "DUsE3dGzTBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "nrxcSuANS3ua"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train.sent_pair.to_list(), train.c_label.to_list())\n",
        "test_dataset = CustomDataset(test.sent_pair.to_list(), test.c_label.to_list())"
      ],
      "metadata": {
        "id": "Gifsau5DTje9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "_xnq7qO8VeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = train.shape[0] # train 전체 길이\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])"
      ],
      "metadata": {
        "id": "YhDSTrpoVhuM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid Dataset len: {len(valid_dataset)}\")\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNajvQrmV225",
        "outputId": "d3760ea1-8cec-4c1d-eb3d-4f0b92b41a60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10494\n",
            "Valid Dataset len: 1167\n",
            "Test Dataset len: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARGUMENT"
      ],
      "metadata": {
        "id": "Iz2aZrF5Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "task = \"sts\"\n",
        "model_checkpoint = \"roberta-base\" \n",
        "train_batch_size = 32\n",
        "eval_batch_size = 64\n",
        "epochs=4\n",
        "patience=1\n",
        "loss_fct = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CiEIKbbuWgTU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "gxJnvrXwWENj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
        "    \n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "45DCZ7_5WGs4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = train_batch_size,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = eval_batch_size,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kGc5rlhW0eK",
        "outputId": "62e01ad2-8c2c-4452-f9ca-e31804313876"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 328\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "PUZIdwDiW8Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RoBerta_baseline(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int, n_label: int):\n",
        "        super(RoBerta_baseline, self).__init__()\n",
        "\n",
        "        self.roberta = RobertaModel.from_pretrained(model_checkpoint)\n",
        "\n",
        "        dropout_rate = 0.1\n",
        "        linear_layer_hidden_size = 32\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Linear(hidden_size, linear_layer_hidden_size),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(dropout_rate),\n",
        "                                        nn.Linear(linear_layer_hidden_size, n_label)\n",
        "                                        )\n",
        "\n",
        "    \n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        \n",
        "        # RoBERTa 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n",
        "        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n",
        "        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n",
        "\n",
        "        logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "mufdkiu5W-Ck"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    \n",
        "    model = RoBerta_baseline(hidden_size=768, n_label=6)\n",
        "    print(model)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(), # update 대상 파라미터를 입력\n",
        "        lr=2e-5,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "pl2aexTXZPYz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a27af7aba6be49f68dc80ef5316d344f",
            "1b559b821d974a3eab35b2b727e108c2",
            "673c95a050bf41f99b43557d93013dc3",
            "c4e833bd4d9341b7ba3fcac0cdf8e80f",
            "422b63e970d14f46b0a14f93b490f736",
            "a78531c50db84b4281a619947d762907",
            "878f75d8e2f54bd18d45d0045057bc43",
            "5223d4e483884a5796c3bc14c7a9dfd8",
            "6383341f55754877982549b7f530bb0f",
            "11bec32124fd4ba181967be1c4106b0b",
            "26de0f5a9aba42378f6358456fe1d2f0",
            "777634d3b25e48328c90c4676180f730",
            "1caadf479133427c82acc2849626ee83",
            "e9454a3d017543f6ac566465f3493e6f",
            "d7e9944754944e30a36178adc6002730",
            "a9e8b9362c8946b1a6d8a68218db84be",
            "2e5233233b5b4a57a708175e7b11ec4f",
            "009bd04b20a3483685b1c1ca07a26081",
            "f4707c5b470547c38a4113d0204bdbb2",
            "4ee9a528be354d9e9d20f56855d9069c",
            "524b8fca03f94ca88aaa50769e691e54",
            "141b8cf7cfbf4381bfa8e2b0c3b6e3d5"
          ]
        },
        "id": "jlnkcrkjb7MK",
        "outputId": "f201e6c1-94cc-4080-b92d-9852d19cb43a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a27af7aba6be49f68dc80ef5316d344f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "777634d3b25e48328c90c4676180f730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBerta_baseline(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "Total train steps with 4 epochs: 1312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = os.path.abspath(os.curdir)\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "      file_name = f'{self.path}/model_ckpt_{self.epoch}'\n",
        "      \n",
        "      torch.save(\n",
        "          {\n",
        "              'epoch': self.epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss' : loss\n",
        "          }, \n",
        "          file_name\n",
        "      )\n",
        "      \n",
        "      print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "gDkDejN5alc8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "    valid_losses = []\n",
        "\n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        valid_losses.append(loss.item())\n",
        "\n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc, valid_losses"
      ],
      "metadata": {
        "id": "D5ayJfKSbi6s"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "        # early_stopping object의 초기화\n",
        "        early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 \n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "            \n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "            # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
        "            #  만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
        "            early_stopping(valid_loss, model)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "                \n",
        "            # checkpoint 저장\n",
        "            early_stopping.save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kLEexE-qbryF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_dataloader, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "DWUpdH3heh93",
        "outputId": "6da1ce16-29bd-46aa-ee19-3858684af8c1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Epoch 1 Train Start*****\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d1a2f7bca7f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-d9776914ab1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, valid_dataloader, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9ef0c4a5d00b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         )\n\u001b[1;32m    859\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         )\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 14.76 GiB total capacity; 12.53 GiB already allocated; 195.75 MiB free; 13.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}