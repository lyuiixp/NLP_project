{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_koelectra_base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEgS2d4LDi4dVNd+LWBxTI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/NLP_project/blob/koelectra%2Fbase-v3/Model_koelectra_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "ZEQ-tAC6zIGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhsY0hJvziNP",
        "outputId": "20da9229-b424-436b-95c5-bbb774e698fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# transformer, datset 설치\n",
        "!pip install transformers datasets\n",
        "#progress bar\n",
        "!pip install fastprogress\n",
        "# Hyperparameter 탐색: optuna 설치\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard 패키지 설치\n",
        "!pip install jupyter-tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHaTl0OG-bvy",
        "outputId": "f3b2ab46-1b0a-4dd8-ac10-4c448f180ce0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyter-tensorboard in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: notebook>=5.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-tensorboard) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (2.11.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.4.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.3.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (23.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=5.0->jupyter-tensorboard) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=5.0->jupyter-tensorboard) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=5.0->jupyter-tensorboard) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (5.0.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (2.15.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=5.0->jupyter-tensorboard) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard extension 설치\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "UwDRmaJt-ZtL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import transformers\n",
        "from numpy.lib.function_base import average\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_metric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# Visualize Loss \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Modeling\n",
        "from transformers import ElectraConfig, ElectraTokenizer, ElectraForSequenceClassification, ElectraModel\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Train\n",
        "from fastprogress.fastprogress import master_bar, progress_bar"
      ],
      "metadata": {
        "id": "Za-SXc_G0uc3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJKSbUoR1qEo",
        "outputId": "44cebf39-8c05-4ed2-8c5f-85edb05232fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "FSdHKK8h1ouK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUGMENT"
      ],
      "metadata": {
        "id": "GcEadgt319Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 64\n",
        "epochs=20\n",
        "patience=2\n",
        "\n",
        "num_label = 1\n",
        "max_seq_len=128\n",
        "learning_rate=5e-5\n",
        "adam_epsilon = 1e-8\n",
        "\n",
        "model_checkpoint = \"monologg/koelectra-base-v3-discriminator\"\n",
        "model_type = \"koelectra-base-v3\"\n",
        "tokenizer = ElectraTokenizer.from_pretrained(model_checkpoint, do_lower_case=False)"
      ],
      "metadata": {
        "id": "vT1ph0_Q1tMN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA FUNC"
      ],
      "metadata": {
        "id": "s10xRcuk1RGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data prepare"
      ],
      "metadata": {
        "id": "x51TnnRV1XIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XOT2hjP30nYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74628bf9-7c91-4222-e6d2-63c71f6e2416"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/AIBootCamp/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lghtyv1f72V2",
        "outputId": "53223914-58d4-4395-fb16-fce5e9e758e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIBootCamp/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfCe9d8572QH",
        "outputId": "24df295b-0918-4d51-a74e-909f2c16f55c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/AIBootCamp/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_all = pd.read_json('./data/klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "test = pd.read_json('./data/klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "lCgB7MLo2NVj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복제거\n",
        "train_all = train_all.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "test = test.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "6FtvIYsU5H4m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid = train_test_split(train_all, test_size=0.1, random_state=seed)"
      ],
      "metadata": {
        "id": "8C0leeOI2Vdi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Utils"
      ],
      "metadata": {
        "id": "o8naMMww1r2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_seed_dataset(df):\n",
        "    # sentence pairs\n",
        "    sent_pairs = [(sent1, sent2) for sent1, sent2 in zip(df['sentence1'], df['sentence2'])]\n",
        "    \n",
        "    # labels(float)\n",
        "    labels = [label['real-label'] for label in df['labels']]\n",
        "\n",
        "    # labels(binary)\n",
        "    b_labels = [label['binary-label'] for label in  df['labels']]\n",
        "    \n",
        "    return sent_pairs, labels, b_labels\n",
        "\n",
        "def encode(tokenizer, sent_pairs):\n",
        "    batch_encoding = tokenizer.batch_encode_plus(\n",
        "                              [(pairs[0], pairs[1]) for pairs in tqdm(sent_pairs, total=len(sent_pairs))], # total : int, 전체 반복량\n",
        "                              max_length=max_seq_len,\n",
        "                              padding=\"max_length\",    \n",
        "                              add_special_tokens=True,\n",
        "                              truncation=True,\n",
        "                              )\n",
        "    return batch_encoding\n",
        "\n",
        "def make_features(sent_pairs, batch_encoding, labels):\n",
        "    features = []\n",
        "    for i in tqdm(range(len(sent_pairs)), total=len(sent_pairs)):\n",
        "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "        if \"token_type_ids\" not in inputs:\n",
        "            inputs[\"token_type_ids\"] = [0] * len(inputs[\"input_ids\"])\n",
        "\n",
        "        feature = {'input_ids':inputs['input_ids'],\n",
        "                  'attention_mask':inputs['attention_mask'],\n",
        "                  'token_type_ids':inputs['token_type_ids'],\n",
        "                  'label':labels[i]\n",
        "                  }\n",
        "        \n",
        "        features.append(feature)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def make_inputs(features):\n",
        "    # inputs\n",
        "    all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
        "    all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
        "\n",
        "    # label\n",
        "    try:\n",
        "      all_labels = torch.tensor([f['label'] for f in features], dtype=torch.float)\n",
        "    except:\n",
        "        raise TypeError # dtype change to torch.float\n",
        "\n",
        "    # dataset\n",
        "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def make_dataloader(dataset, mode:str):\n",
        "    assert mode in ['train', 'valid', 'test']\n",
        "\n",
        "    if mode == \"train\":\n",
        "        dataloader = DataLoader(dataset = dataset, # (input_ids, attention_mask, token_type_ids, labels)\n",
        "                                sampler = RandomSampler(dataset), \n",
        "                                batch_size = train_batch_size)\n",
        "    elif mode == \"valid\":\n",
        "        dataloader = DataLoader(dataset = dataset, \n",
        "                                sampler = RandomSampler(dataset), \n",
        "                                batch_size = eval_batch_size)\n",
        "    elif mode == \"test\":\n",
        "        dataloader = DataLoader(dataset = dataset, \n",
        "                                sampler = SequentialSampler(dataset), \n",
        "                                batch_size = eval_batch_size)\n",
        "    else:\n",
        "        raise AssertionError(mode) # write mode\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "wlu_iutg1p_3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA SET"
      ],
      "metadata": {
        "id": "4YVSqs1Q4HUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "t_sent_pairs, t_labels, t_b_labels = make_seed_dataset(train)\n",
        "\n",
        "# validation dataset\n",
        "v_sent_pairs, v_labels, v_b_labels = make_seed_dataset(valid)\n",
        "\n",
        "# dev dataset\n",
        "d_sent_pairs, d_labels, d_b_labels = make_seed_dataset(test)"
      ],
      "metadata": {
        "id": "bkN1xkZ1K-7b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding\n",
        "encoded_train = encode(tokenizer, t_sent_pairs)\n",
        "encoded_valid = encode(tokenizer, v_sent_pairs) \n",
        "encoded_test = encode(tokenizer, d_sent_pairs)"
      ],
      "metadata": {
        "id": "eU4gJ35nAEMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0fc4a1-d164-4c9b-c491-cfeca9fd3af5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10494/10494 [00:00<00:00, 554205.82it/s]\n",
            "100%|██████████| 1167/1167 [00:00<00:00, 580566.10it/s]\n",
            "100%|██████████| 519/519 [00:00<00:00, 617544.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get features \n",
        "train_features = make_features(t_sent_pairs, encoded_train, t_labels)\n",
        "valid_features = make_features(v_sent_pairs, encoded_valid, v_labels)\n",
        "test_features = make_features(d_sent_pairs, encoded_test, d_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yr5mb4i57Wt",
        "outputId": "0fcecaec-4bb3-49d1-cea8-43e6646e372c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10494/10494 [00:00<00:00, 109016.35it/s]\n",
            "100%|██████████| 1167/1167 [00:00<00:00, 92921.88it/s]\n",
            "100%|██████████| 519/519 [00:00<00:00, 90713.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make inputs\n",
        "train_dataset = make_inputs(train_features)\n",
        "valid_dataset = make_inputs(valid_features)\n",
        "test_dataset = make_inputs(test_features)"
      ],
      "metadata": {
        "id": "l01QYGYp6GNu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loader\n",
        "train_dataloader = make_dataloader(train_dataset, mode='train')\n",
        "valid_dataloader = make_dataloader(valid_dataset, mode='valid')\n",
        "dev_dataloader = make_dataloader(test_dataset, mode='test')"
      ],
      "metadata": {
        "id": "moCYtqSB6YXO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preset(logging, DIR, metric)"
      ],
      "metadata": {
        "id": "9xUn1oAj65JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_CUR_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L9jMddqk7NKx",
        "outputId": "d442dde8-4a1d-4d2e-8040-a711c199460f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/AIBootCamp/NLP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서보드 dir 정의 \n",
        "logdir_path = os.path.join(_CUR_DIR,\"KoELECTRA/koelectra_log\") # log 파일을 저장할 경로를 지정 \n",
        "writer = SummaryWriter(logdir_path)"
      ],
      "metadata": {
        "id": "RnbdtgJE-hIS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '__main__' 이름의 logger 생성\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "xnXFz-Oy64QS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(_CUR_DIR,\"KoELECTRA/koelectra_tensor\")"
      ],
      "metadata": {
        "id": "ud8WASuH7AlC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f1과 pearson 메트릭 불러오기 \n",
        "metric_f1 = load_metric(\"f1\") \n",
        "metric_pearson = load_metric(\"pearsonr\")"
      ],
      "metadata": {
        "id": "zjK79Vnb_clS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "metadata": {
        "id": "vo7bItoy7dPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Utils"
      ],
      "metadata": {
        "id": "8oSyxKso75ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\"model_type\": \"koelectra-base-v3\"}"
      ],
      "metadata": {
        "id": "cdc6bNDvLuu-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "        file_name = f'{self.path}/model.ckpt.best_{epoch}'\n",
        "        \n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss' : loss\n",
        "            }, \n",
        "            file_name\n",
        "        )\n",
        "      \n",
        "        print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "ErohdH4Z738y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_logger():\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_metrics(labels, preds):\n",
        "    predict_f1 = [1 if i>=3.0 else 0 for i in preds] # 3.0 이상-> 1, 3.0 미만 -> 0으로 변환\n",
        "    labels_f1 = [1 if i>=3.0 else 0 for i in labels] # 3.0 이상-> 1, 3.0 미만 -> 0으로 변환\n",
        "\n",
        "    pr = metric_pearson.compute(predictions=preds, # peason r 계산\n",
        "                                   references=labels)\n",
        "\n",
        "    f1 = metric_f1.compute(predictions=predict_f1,   # f1\n",
        "                                     references=labels_f1)\n",
        "    return {'pearsonr' : pr,\n",
        "             'f1' : f1}"
      ],
      "metadata": {
        "id": "OwF8o_9S-udQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader, mode, global_step=None):\n",
        "    results = {}\n",
        "\n",
        "    # Eval!\n",
        "    if global_step != None:\n",
        "        logger.info(\"***** Running evaluation on {} dataset ({} step) *****\".format(mode, global_step))\n",
        "    else:\n",
        "        logger.info(\"***** Running evaluation on {} dataset *****\".format(mode))\n",
        "    logger.info(\"  Num examples = {}\".format(len(valid_dataset)))\n",
        "    logger.info(\"  Eval Batch size = {}\".format(eval_batch_size))\n",
        "    \n",
        "    loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    \n",
        "    for batch in progress_bar(valid_dataloader):\n",
        "        model.eval()\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "\n",
        "        # no_grad\n",
        "        with torch.no_grad():\n",
        "            # inputs\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "                \"labels\": batch[3]\n",
        "            }\n",
        "            \n",
        "            # outputs\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # loss and logits\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "            loss += tmp_eval_loss.mean().item()\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "        # Get preds and out_label_ids\n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    # average valid loss per epoch\n",
        "    loss = loss / nb_eval_steps\n",
        "    \n",
        "    # preds depending on the type of task\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Pearson correlation coefficient and Spearman correlation coefficient\n",
        "    result = compute_metrics(out_label_ids, preds)\n",
        "    results.update(result)\n",
        "\n",
        "    return results, loss"
      ],
      "metadata": {
        "id": "QXuk_nViFuM9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, valid_dataloader=None):\n",
        "    # early_stopping object의 초기화\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True, path=save_path)\n",
        "    \n",
        "    # train loss and val loss per epoch\n",
        "    avg_tr_loss = []\n",
        "    avg_val_loss = []\n",
        "\n",
        "     # Prepare optimizer and schedule\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
        "         'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    # train total steps\n",
        "    total_steps  = len(train_dataloader) * epochs\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                      lr=5e-5,\n",
        "                      eps=adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n",
        "                                                num_warmup_steps=0, \n",
        "                                                num_training_steps=total_steps)\n",
        "    \n",
        "    \n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataloader))\n",
        "    logger.info(\"  Num Epochs = %d\", epochs)\n",
        "    logger.info(\"  Total train batch size = %d\", train_batch_size)\n",
        "    logger.info(\"  Total optimization steps = %d\", total_steps)\n",
        "\n",
        "    # Set step and loss\n",
        "    global_step, batch_step = 0, 0\n",
        "    tr_loss, batch_loss = 0.0 ,0.0\n",
        "\n",
        "    # zero_grad\n",
        "    model.zero_grad()\n",
        "\n",
        "    # train_dataloaer 학습을 epochs만큼 반복\n",
        "    mb = master_bar(range(int(epochs)))\n",
        "    for epoch in tqdm(mb):\n",
        "        #progress bar\n",
        "        epoch_iterator = progress_bar(train_dataloader, parent=mb)\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            batch_step+=1\n",
        "            \n",
        "            # train mode\n",
        "            model.train()\n",
        "            \n",
        "            # inputs to device\n",
        "            batch = tuple(item.to(device) for item in batch) # tuple(item.to(args.device) for item in batch)\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "                \"labels\": batch[3]\n",
        "            }\n",
        "            \n",
        "            # forward\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # loss \n",
        "            loss = outputs[0]\n",
        "\n",
        "            # backward\n",
        "            loss.backward()\n",
        "\n",
        "            # loss of both batch and tr\n",
        "            batch_loss += loss.item()\n",
        "            tr_loss += loss.item()\n",
        "            \n",
        "            # gradient clipping (max_norm = 1)\n",
        "            clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "                \n",
        "            # Update optimizer & scheduler\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # initialize gradient by each batch \n",
        "            model.zero_grad()\n",
        "            \n",
        "            # Print out the batch_loss and the learning rate by every 10 batches\n",
        "            if (step % 10 == 0 and step != 0):\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_step:.4f}\")\n",
        "                \n",
        "                # 학습 loss 기록 tensorboard\n",
        "                writer.add_scalar(\n",
        "                    tag = \"Train Loss\",\n",
        "                    scalar_value = batch_loss / batch_step,\n",
        "                    global_step = epoch * len(train_dataloader) + step\n",
        "                )\n",
        "\n",
        "                # 학습 learning rate 기록\n",
        "                writer.add_scalar(\n",
        "                    tag = \"Train LR\",\n",
        "                    scalar_value = optimizer.param_groups[0]['lr'],\n",
        "                    global_step = epoch * len(train_dataloader) + step\n",
        "                )\n",
        "\n",
        "                # Reset batch_loss and batch_step\n",
        "                batch_loss, batch_step = 0.0, 0\n",
        "                \n",
        "            global_step += 1\n",
        "\n",
        "        # Average train loss per epoch\n",
        "        avg_train_loss = round(tr_loss / global_step, 4)\n",
        "        avg_tr_loss.append(avg_train_loss)\n",
        "        print(f\"Epoch {epoch} Train Loss : {avg_tr_loss}\")\n",
        "\n",
        "        # Validate!\n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            results, val_loss = validate(model, valid_dataloader, \"valid\", global_step)\n",
        "            avg_val_loss.append(val_loss)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {val_loss:.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train and Valid Finish*****\\n\")\n",
        "            \n",
        "            # val loss 기록 tensorboard\n",
        "            writer.add_scalar(\n",
        "                tag = \"Valid Loss\",\n",
        "                scalar_value = val_loss,\n",
        "                global_step = epoch\n",
        "            )\n",
        "        early_stopping(val_loss, model, optimizer, scheduler, epoch)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        else:\n",
        "          early_stopping.save_checkpoint(model, optimizer, scheduler, epoch, loss)\n",
        "\n",
        "    print(\"Train Completed. End Program.\")\n",
        "    writer.close()  #tensorboard기록중지\n",
        "    return global_step, tr_loss / global_step, avg_tr_loss, avg_val_loss\n"
      ],
      "metadata": {
        "id": "djcq2zjn7kZ4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    init_logger()\n",
        "      \n",
        "    model =  ElectraForSequenceClassification.from_pretrained(model_checkpoint,num_labels=num_label).cuda()\n",
        "\n",
        "    global_step, tr_loss, avg_tr_loss_li, avg_val_loss_li = train(model, train_dataloader, valid_dataloader)\n",
        "    logger.info(\" global_step = {}, average loss = {}\".format(global_step, tr_loss))\n",
        "\n",
        "\n",
        "    return  avg_tr_loss_li, avg_val_loss_li"
      ],
      "metadata": {
        "id": "FSjB_VE3_JAF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 / 검증\n",
        "avg_tr_loss_li, avg_val_loss_li = main()"
      ],
      "metadata": {
        "id": "j5Urh7Cf_TJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d2dfd42-0bd9-4132-e369-2c028fe30003"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "06/01/2022 17:18:19 - INFO - __main__ -   ***** Running training *****\n",
            "06/01/2022 17:18:19 - INFO - __main__ -     Num examples = 328\n",
            "06/01/2022 17:18:19 - INFO - __main__ -     Num Epochs = 20\n",
            "06/01/2022 17:18:19 - INFO - __main__ -     Total train batch size = 32\n",
            "06/01/2022 17:18:19 - INFO - __main__ -     Total optimization steps = 6560\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='4' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      20.00% [4/20 09:27<37:50]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "      <progress value='328' class='' max='328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [328/328 02:09<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Step : 10, LR : 4.9916158536585364e-05, Avg Loss : 5.5296\n",
            "Epoch: 0, Step : 20, LR : 4.983993902439025e-05, Avg Loss : 3.2281\n",
            "Epoch: 0, Step : 30, LR : 4.976371951219512e-05, Avg Loss : 1.4918\n",
            "Epoch: 0, Step : 40, LR : 4.96875e-05, Avg Loss : 0.4453\n",
            "Epoch: 0, Step : 50, LR : 4.961128048780488e-05, Avg Loss : 0.4402\n",
            "Epoch: 0, Step : 60, LR : 4.953506097560976e-05, Avg Loss : 0.4189\n",
            "Epoch: 0, Step : 70, LR : 4.945884146341463e-05, Avg Loss : 0.4798\n",
            "Epoch: 0, Step : 80, LR : 4.938262195121951e-05, Avg Loss : 0.2526\n",
            "Epoch: 0, Step : 90, LR : 4.930640243902439e-05, Avg Loss : 0.3214\n",
            "Epoch: 0, Step : 100, LR : 4.923018292682927e-05, Avg Loss : 0.2271\n",
            "Epoch: 0, Step : 110, LR : 4.915396341463414e-05, Avg Loss : 0.2491\n",
            "Epoch: 0, Step : 120, LR : 4.907774390243903e-05, Avg Loss : 0.2275\n",
            "Epoch: 0, Step : 130, LR : 4.90015243902439e-05, Avg Loss : 0.2542\n",
            "Epoch: 0, Step : 140, LR : 4.892530487804878e-05, Avg Loss : 0.2327\n",
            "Epoch: 0, Step : 150, LR : 4.884908536585366e-05, Avg Loss : 0.2659\n",
            "Epoch: 0, Step : 160, LR : 4.877286585365854e-05, Avg Loss : 0.2666\n",
            "Epoch: 0, Step : 170, LR : 4.869664634146341e-05, Avg Loss : 0.2341\n",
            "Epoch: 0, Step : 180, LR : 4.862042682926829e-05, Avg Loss : 0.2226\n",
            "Epoch: 0, Step : 190, LR : 4.854420731707317e-05, Avg Loss : 0.1728\n",
            "Epoch: 0, Step : 200, LR : 4.846798780487805e-05, Avg Loss : 0.1929\n",
            "Epoch: 0, Step : 210, LR : 4.839176829268293e-05, Avg Loss : 0.2375\n",
            "Epoch: 0, Step : 220, LR : 4.831554878048781e-05, Avg Loss : 0.2056\n",
            "Epoch: 0, Step : 230, LR : 4.823932926829269e-05, Avg Loss : 0.2442\n",
            "Epoch: 0, Step : 240, LR : 4.816310975609756e-05, Avg Loss : 0.1888\n",
            "Epoch: 0, Step : 250, LR : 4.808689024390244e-05, Avg Loss : 0.2085\n",
            "Epoch: 0, Step : 260, LR : 4.801067073170732e-05, Avg Loss : 0.2055\n",
            "Epoch: 0, Step : 270, LR : 4.79344512195122e-05, Avg Loss : 0.1935\n",
            "Epoch: 0, Step : 280, LR : 4.785823170731707e-05, Avg Loss : 0.1926\n",
            "Epoch: 0, Step : 290, LR : 4.778201219512196e-05, Avg Loss : 0.1705\n",
            "Epoch: 0, Step : 300, LR : 4.770579268292683e-05, Avg Loss : 0.1882\n",
            "Epoch: 0, Step : 310, LR : 4.762957317073171e-05, Avg Loss : 0.1995\n",
            "Epoch: 0, Step : 320, LR : 4.755335365853659e-05, Avg Loss : 0.1896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:20:27 - INFO - __main__ -   ***** Running evaluation on valid dataset (328 step) *****\n",
            "06/01/2022 17:20:27 - INFO - __main__ -     Num examples = 1167\n",
            "06/01/2022 17:20:27 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Train Loss : [0.5567]\n",
            "*****Epoch 0 Valid Start*****\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [19/19 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Valid Loss : 0.1966\n",
            "*****Epoch 0 Train and Valid Finish*****\n",
            "\n",
            "Saving epoch 0 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r1it [02:23, 143.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving epoch 0 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_0\n",
            "Epoch: 1, Step : 10, LR : 4.741615853658537e-05, Avg Loss : 0.1476\n",
            "Epoch: 1, Step : 20, LR : 4.733993902439024e-05, Avg Loss : 0.1482\n",
            "Epoch: 1, Step : 30, LR : 4.726371951219513e-05, Avg Loss : 0.1345\n",
            "Epoch: 1, Step : 40, LR : 4.71875e-05, Avg Loss : 0.1290\n",
            "Epoch: 1, Step : 50, LR : 4.711128048780488e-05, Avg Loss : 0.1365\n",
            "Epoch: 1, Step : 60, LR : 4.703506097560976e-05, Avg Loss : 0.1357\n",
            "Epoch: 1, Step : 70, LR : 4.695884146341464e-05, Avg Loss : 0.1297\n",
            "Epoch: 1, Step : 80, LR : 4.688262195121951e-05, Avg Loss : 0.1290\n",
            "Epoch: 1, Step : 90, LR : 4.680640243902439e-05, Avg Loss : 0.1346\n",
            "Epoch: 1, Step : 100, LR : 4.673018292682927e-05, Avg Loss : 0.1516\n",
            "Epoch: 1, Step : 110, LR : 4.665396341463415e-05, Avg Loss : 0.1534\n",
            "Epoch: 1, Step : 120, LR : 4.657774390243902e-05, Avg Loss : 0.1259\n",
            "Epoch: 1, Step : 130, LR : 4.650152439024391e-05, Avg Loss : 0.1723\n",
            "Epoch: 1, Step : 140, LR : 4.642530487804878e-05, Avg Loss : 0.1269\n",
            "Epoch: 1, Step : 150, LR : 4.634908536585366e-05, Avg Loss : 0.1458\n",
            "Epoch: 1, Step : 160, LR : 4.6272865853658534e-05, Avg Loss : 0.1225\n",
            "Epoch: 1, Step : 170, LR : 4.619664634146342e-05, Avg Loss : 0.1225\n",
            "Epoch: 1, Step : 180, LR : 4.612042682926829e-05, Avg Loss : 0.1442\n",
            "Epoch: 1, Step : 190, LR : 4.604420731707317e-05, Avg Loss : 0.1201\n",
            "Epoch: 1, Step : 200, LR : 4.596798780487805e-05, Avg Loss : 0.1367\n",
            "Epoch: 1, Step : 210, LR : 4.589176829268293e-05, Avg Loss : 0.1336\n",
            "Epoch: 1, Step : 220, LR : 4.58155487804878e-05, Avg Loss : 0.1215\n",
            "Epoch: 1, Step : 230, LR : 4.573932926829269e-05, Avg Loss : 0.1805\n",
            "Epoch: 1, Step : 240, LR : 4.566310975609756e-05, Avg Loss : 0.1201\n",
            "Epoch: 1, Step : 250, LR : 4.558689024390244e-05, Avg Loss : 0.1642\n",
            "Epoch: 1, Step : 260, LR : 4.551067073170731e-05, Avg Loss : 0.1205\n",
            "Epoch: 1, Step : 270, LR : 4.54344512195122e-05, Avg Loss : 0.1266\n",
            "Epoch: 1, Step : 280, LR : 4.535823170731707e-05, Avg Loss : 0.1437\n",
            "Epoch: 1, Step : 290, LR : 4.528201219512195e-05, Avg Loss : 0.1467\n",
            "Epoch: 1, Step : 300, LR : 4.520579268292684e-05, Avg Loss : 0.1361\n",
            "Epoch: 1, Step : 310, LR : 4.512957317073171e-05, Avg Loss : 0.1197\n",
            "Epoch: 1, Step : 320, LR : 4.505335365853659e-05, Avg Loss : 0.1235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:22:52 - INFO - __main__ -   ***** Running evaluation on valid dataset (656 step) *****\n",
            "06/01/2022 17:22:52 - INFO - __main__ -     Num examples = 1167\n",
            "06/01/2022 17:22:52 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss : [0.5567, 0.3464]\n",
            "*****Epoch 1 Valid Start*****\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [19/19 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Valid Loss : 0.2248\n",
            "*****Epoch 1 Train and Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [04:42, 140.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving epoch 1 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_1\n",
            "Epoch: 2, Step : 10, LR : 4.491615853658537e-05, Avg Loss : 0.1004\n",
            "Epoch: 2, Step : 20, LR : 4.483993902439025e-05, Avg Loss : 0.1026\n",
            "Epoch: 2, Step : 30, LR : 4.476371951219512e-05, Avg Loss : 0.0782\n",
            "Epoch: 2, Step : 40, LR : 4.46875e-05, Avg Loss : 0.0881\n",
            "Epoch: 2, Step : 50, LR : 4.461128048780488e-05, Avg Loss : 0.1152\n",
            "Epoch: 2, Step : 60, LR : 4.453506097560976e-05, Avg Loss : 0.1004\n",
            "Epoch: 2, Step : 70, LR : 4.445884146341463e-05, Avg Loss : 0.0880\n",
            "Epoch: 2, Step : 80, LR : 4.438262195121952e-05, Avg Loss : 0.1103\n",
            "Epoch: 2, Step : 90, LR : 4.430640243902439e-05, Avg Loss : 0.0976\n",
            "Epoch: 2, Step : 100, LR : 4.423018292682927e-05, Avg Loss : 0.1013\n",
            "Epoch: 2, Step : 110, LR : 4.415396341463415e-05, Avg Loss : 0.1075\n",
            "Epoch: 2, Step : 120, LR : 4.407774390243903e-05, Avg Loss : 0.0893\n",
            "Epoch: 2, Step : 130, LR : 4.40015243902439e-05, Avg Loss : 0.0750\n",
            "Epoch: 2, Step : 140, LR : 4.392530487804878e-05, Avg Loss : 0.0937\n",
            "Epoch: 2, Step : 150, LR : 4.384908536585366e-05, Avg Loss : 0.0827\n",
            "Epoch: 2, Step : 160, LR : 4.377286585365854e-05, Avg Loss : 0.0860\n",
            "Epoch: 2, Step : 170, LR : 4.369664634146341e-05, Avg Loss : 0.0792\n",
            "Epoch: 2, Step : 180, LR : 4.36204268292683e-05, Avg Loss : 0.0903\n",
            "Epoch: 2, Step : 190, LR : 4.354420731707317e-05, Avg Loss : 0.0847\n",
            "Epoch: 2, Step : 200, LR : 4.346798780487805e-05, Avg Loss : 0.1089\n",
            "Epoch: 2, Step : 210, LR : 4.339176829268293e-05, Avg Loss : 0.1015\n",
            "Epoch: 2, Step : 220, LR : 4.331554878048781e-05, Avg Loss : 0.0822\n",
            "Epoch: 2, Step : 230, LR : 4.323932926829268e-05, Avg Loss : 0.0939\n",
            "Epoch: 2, Step : 240, LR : 4.316310975609756e-05, Avg Loss : 0.0893\n",
            "Epoch: 2, Step : 250, LR : 4.308689024390244e-05, Avg Loss : 0.0806\n",
            "Epoch: 2, Step : 260, LR : 4.301067073170732e-05, Avg Loss : 0.0879\n",
            "Epoch: 2, Step : 270, LR : 4.293445121951219e-05, Avg Loss : 0.0864\n",
            "Epoch: 2, Step : 280, LR : 4.285823170731708e-05, Avg Loss : 0.0886\n",
            "Epoch: 2, Step : 290, LR : 4.278201219512195e-05, Avg Loss : 0.1090\n",
            "Epoch: 2, Step : 300, LR : 4.270579268292683e-05, Avg Loss : 0.0972\n",
            "Epoch: 2, Step : 310, LR : 4.262957317073171e-05, Avg Loss : 0.1013\n",
            "Epoch: 2, Step : 320, LR : 4.255335365853659e-05, Avg Loss : 0.0754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:25:11 - INFO - __main__ -   ***** Running evaluation on valid dataset (984 step) *****\n",
            "06/01/2022 17:25:11 - INFO - __main__ -     Num examples = 1167\n",
            "06/01/2022 17:25:11 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Train Loss : [0.5567, 0.3464, 0.2617]\n",
            "*****Epoch 2 Valid Start*****\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [19/19 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Valid Loss : 0.1435\n",
            "*****Epoch 2 Train and Valid Finish*****\n",
            "\n",
            "Saving epoch 2 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [07:07, 142.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving epoch 2 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_2\n",
            "Epoch: 3, Step : 10, LR : 4.2416158536585364e-05, Avg Loss : 0.0764\n",
            "Epoch: 3, Step : 20, LR : 4.2339939024390244e-05, Avg Loss : 0.0650\n",
            "Epoch: 3, Step : 30, LR : 4.226371951219512e-05, Avg Loss : 0.0547\n",
            "Epoch: 3, Step : 40, LR : 4.21875e-05, Avg Loss : 0.0768\n",
            "Epoch: 3, Step : 50, LR : 4.211128048780488e-05, Avg Loss : 0.0672\n",
            "Epoch: 3, Step : 60, LR : 4.203506097560976e-05, Avg Loss : 0.0721\n",
            "Epoch: 3, Step : 70, LR : 4.195884146341464e-05, Avg Loss : 0.0669\n",
            "Epoch: 3, Step : 80, LR : 4.188262195121951e-05, Avg Loss : 0.0723\n",
            "Epoch: 3, Step : 90, LR : 4.180640243902439e-05, Avg Loss : 0.0799\n",
            "Epoch: 3, Step : 100, LR : 4.173018292682927e-05, Avg Loss : 0.0688\n",
            "Epoch: 3, Step : 110, LR : 4.165396341463415e-05, Avg Loss : 0.0720\n",
            "Epoch: 3, Step : 120, LR : 4.157774390243902e-05, Avg Loss : 0.0655\n",
            "Epoch: 3, Step : 130, LR : 4.150152439024391e-05, Avg Loss : 0.0653\n",
            "Epoch: 3, Step : 140, LR : 4.142530487804878e-05, Avg Loss : 0.0788\n",
            "Epoch: 3, Step : 150, LR : 4.134908536585366e-05, Avg Loss : 0.0555\n",
            "Epoch: 3, Step : 160, LR : 4.127286585365854e-05, Avg Loss : 0.0714\n",
            "Epoch: 3, Step : 170, LR : 4.119664634146342e-05, Avg Loss : 0.0702\n",
            "Epoch: 3, Step : 180, LR : 4.112042682926829e-05, Avg Loss : 0.0653\n",
            "Epoch: 3, Step : 190, LR : 4.104420731707317e-05, Avg Loss : 0.0618\n",
            "Epoch: 3, Step : 200, LR : 4.096798780487805e-05, Avg Loss : 0.0668\n",
            "Epoch: 3, Step : 210, LR : 4.089176829268293e-05, Avg Loss : 0.0562\n",
            "Epoch: 3, Step : 220, LR : 4.08155487804878e-05, Avg Loss : 0.0605\n",
            "Epoch: 3, Step : 230, LR : 4.073932926829269e-05, Avg Loss : 0.0654\n",
            "Epoch: 3, Step : 240, LR : 4.066310975609756e-05, Avg Loss : 0.0854\n",
            "Epoch: 3, Step : 250, LR : 4.058689024390244e-05, Avg Loss : 0.0734\n",
            "Epoch: 3, Step : 260, LR : 4.051067073170732e-05, Avg Loss : 0.0576\n",
            "Epoch: 3, Step : 270, LR : 4.04344512195122e-05, Avg Loss : 0.0659\n",
            "Epoch: 3, Step : 280, LR : 4.035823170731707e-05, Avg Loss : 0.0598\n",
            "Epoch: 3, Step : 290, LR : 4.028201219512195e-05, Avg Loss : 0.0693\n",
            "Epoch: 3, Step : 300, LR : 4.020579268292683e-05, Avg Loss : 0.0790\n",
            "Epoch: 3, Step : 310, LR : 4.012957317073171e-05, Avg Loss : 0.0913\n",
            "Epoch: 3, Step : 320, LR : 4.005335365853658e-05, Avg Loss : 0.0690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:27:37 - INFO - __main__ -   ***** Running evaluation on valid dataset (1312 step) *****\n",
            "06/01/2022 17:27:37 - INFO - __main__ -     Num examples = 1167\n",
            "06/01/2022 17:27:37 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Train Loss : [0.5567, 0.3464, 0.2617, 0.2134]\n",
            "*****Epoch 3 Valid Start*****\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [19/19 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Valid Loss : 0.1918\n",
            "*****Epoch 3 Train and Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [09:27, 141.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving epoch 3 checkpoint at /content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor/model.ckpt.best_3\n",
            "Epoch: 4, Step : 10, LR : 3.991615853658537e-05, Avg Loss : 0.0646\n",
            "Epoch: 4, Step : 20, LR : 3.9839939024390244e-05, Avg Loss : 0.0476\n",
            "Epoch: 4, Step : 30, LR : 3.976371951219512e-05, Avg Loss : 0.0494\n",
            "Epoch: 4, Step : 40, LR : 3.96875e-05, Avg Loss : 0.0541\n",
            "Epoch: 4, Step : 50, LR : 3.961128048780488e-05, Avg Loss : 0.0555\n",
            "Epoch: 4, Step : 60, LR : 3.9535060975609754e-05, Avg Loss : 0.0532\n",
            "Epoch: 4, Step : 70, LR : 3.9458841463414634e-05, Avg Loss : 0.0565\n",
            "Epoch: 4, Step : 80, LR : 3.938262195121951e-05, Avg Loss : 0.0706\n",
            "Epoch: 4, Step : 90, LR : 3.930640243902439e-05, Avg Loss : 0.0529\n",
            "Epoch: 4, Step : 100, LR : 3.9230182926829265e-05, Avg Loss : 0.0497\n",
            "Epoch: 4, Step : 110, LR : 3.915396341463415e-05, Avg Loss : 0.0564\n",
            "Epoch: 4, Step : 120, LR : 3.9077743902439024e-05, Avg Loss : 0.0462\n",
            "Epoch: 4, Step : 130, LR : 3.90015243902439e-05, Avg Loss : 0.0518\n",
            "Epoch: 4, Step : 140, LR : 3.892530487804878e-05, Avg Loss : 0.0482\n",
            "Epoch: 4, Step : 150, LR : 3.884908536585366e-05, Avg Loss : 0.0512\n",
            "Epoch: 4, Step : 160, LR : 3.877286585365854e-05, Avg Loss : 0.0504\n",
            "Epoch: 4, Step : 170, LR : 3.8696646341463413e-05, Avg Loss : 0.0556\n",
            "Epoch: 4, Step : 180, LR : 3.86204268292683e-05, Avg Loss : 0.0601\n",
            "Epoch: 4, Step : 190, LR : 3.854420731707317e-05, Avg Loss : 0.0433\n",
            "Epoch: 4, Step : 200, LR : 3.846798780487805e-05, Avg Loss : 0.0628\n",
            "Epoch: 4, Step : 210, LR : 3.839176829268293e-05, Avg Loss : 0.0527\n",
            "Epoch: 4, Step : 220, LR : 3.831554878048781e-05, Avg Loss : 0.0594\n",
            "Epoch: 4, Step : 230, LR : 3.823932926829268e-05, Avg Loss : 0.0592\n",
            "Epoch: 4, Step : 240, LR : 3.816310975609756e-05, Avg Loss : 0.0512\n",
            "Epoch: 4, Step : 250, LR : 3.808689024390244e-05, Avg Loss : 0.0478\n",
            "Epoch: 4, Step : 260, LR : 3.801067073170732e-05, Avg Loss : 0.0583\n",
            "Epoch: 4, Step : 270, LR : 3.793445121951219e-05, Avg Loss : 0.0526\n",
            "Epoch: 4, Step : 280, LR : 3.785823170731708e-05, Avg Loss : 0.0492\n",
            "Epoch: 4, Step : 290, LR : 3.778201219512195e-05, Avg Loss : 0.0502\n",
            "Epoch: 4, Step : 300, LR : 3.770579268292683e-05, Avg Loss : 0.0599\n",
            "Epoch: 4, Step : 310, LR : 3.762957317073171e-05, Avg Loss : 0.0565\n",
            "Epoch: 4, Step : 320, LR : 3.755335365853659e-05, Avg Loss : 0.0548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:29:56 - INFO - __main__ -   ***** Running evaluation on valid dataset (1640 step) *****\n",
            "06/01/2022 17:29:56 - INFO - __main__ -     Num examples = 1167\n",
            "06/01/2022 17:29:56 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Train Loss : [0.5567, 0.3464, 0.2617, 0.2134, 0.1815]\n",
            "*****Epoch 4 Valid Start*****\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [19/19 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "\r4it [11:41, 175.33s/it]\n",
            "06/01/2022 17:30:00 - INFO - __main__ -    global_step = 1640, average loss = 0.181512268799607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Valid Loss : 0.1751\n",
            "*****Epoch 4 Train and Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            "Train Completed. End Program.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss 변화 시각화\n",
        "val_loss = {'train_loss' : avg_tr_loss_li,\n",
        "            'val_loss' : avg_val_loss_li,\n",
        "            'epoch' : [1, 2, 3, 4, 5]}\n",
        "loss_df = pd.DataFrame(data=val_loss)\n",
        "\n",
        "sns.lineplot(x='epoch', y='train_loss', data=loss_df, label='train_loss')\n",
        "sns.lineplot(x='epoch', y='val_loss', data=loss_df, label='val_loss')\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('LOSS')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "CDS6CvoSUdVE",
        "outputId": "1d4f86ed-caf3-4eb6-d81c-1ef4e3f06e20"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTION"
      ],
      "metadata": {
        "id": "ivkBBEqrVEL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "path = '/content/drive/MyDrive/AIBootCamp/NLP/KoELECTRA/koelectra_tensor'\n",
        "checkpoint = torch.load(f'{path}/model.ckpt.best_3')"
      ],
      "metadata": {
        "id": "Mjc3BB54VAyu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckpt keys\n",
        "checkpoint.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W7RgN2RVUWY",
        "outputId": "5299ad5c-cd71-4750-9e14-3df917067a97"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "  return ElectraForSequenceClassification.from_pretrained(model_checkpoint,num_labels=num_label).cuda()"
      ],
      "metadata": {
        "id": "0fFAIoRRVWar"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoIo0ZzIVk9a",
        "outputId": "c9b45226-6ab9-48fd-bdf5-2918a8ea016c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_state_dict\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJWIEEatWRtM",
        "outputId": "f998dc5a-72a0-48ff-b38c-b82ccc2a6d76"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader, mode, global_step=None):\n",
        "\n",
        "    \n",
        "    if global_step != None:\n",
        "        logger.info(\"***** Running test on {} dataset ({} step) *****\".format(mode, global_step))\n",
        "    else:\n",
        "        logger.info(\"***** Running test on {} dataset *****\".format(mode))\n",
        "    logger.info(\"  Num examples = {}\".format(len(test_dataset)))\n",
        "    logger.info(\"  Eval Batch size = {}\".format(eval_batch_size))\n",
        "    \n",
        "    # loss, steps, preds, labels\n",
        "    loss = 0.0\n",
        "    nb_test_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    \n",
        "    # Predict !\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    for batch in progress_bar(dev_dataloader):\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "\n",
        "        # no_grad\n",
        "        with torch.no_grad():\n",
        "            # inputs\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "                \"labels\": batch[3]\n",
        "            }\n",
        "\n",
        "            # outputs\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # loss and logits\n",
        "            tmp_test_loss, logits = outputs[:2]\n",
        "            loss += tmp_test_loss.mean().item()\n",
        "        \n",
        "        nb_test_steps += 1\n",
        "\n",
        "        # preds and labels\n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "\n",
        "    ################################### RETURNS ###################################\n",
        "    \n",
        "    # average loss\n",
        "    loss = loss / nb_test_steps\n",
        "  \n",
        "\n",
        "    \"\"\" returns info\n",
        "    preds           :  predictions(float)\n",
        "    out_label_ids   :  labels(float)\n",
        "    loss            :  loss of prediction\n",
        "    \"\"\"\n",
        "    return preds, out_label_ids, loss"
      ],
      "metadata": {
        "id": "knmPKD9sVtwz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict !\n",
        "preds, out_label_ids, loss = predict(model, dev_dataloader, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "bIUEwa95V-IP",
        "outputId": "8f0035ba-1af8-4814-8d03-2f52d788e65e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/01/2022 17:51:22 - INFO - __main__ -   ***** Running test on test dataset *****\n",
            "06/01/2022 17:51:22 - INFO - __main__ -     Num examples = 519\n",
            "06/01/2022 17:51:22 - INFO - __main__ -     Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='9' class='' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [9/9 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_bi_label = [1 if i >= 3.0 else 0 for i in preds]"
      ],
      "metadata": {
        "id": "mOXcyR0uXil1"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn import metrics as sklearn_metrics"
      ],
      "metadata": {
        "id": "EI7azXTKXOYJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_f1 = sklearn_metrics.f1_score(d_b_labels, pred_bi_label, average=\"macro\")\n",
        "test_pearson = pearsonr(d_labels, preds)[0][0]"
      ],
      "metadata": {
        "id": "f2ze233FWnP0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pearson[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bauMEq5tZtEI",
        "outputId": "ddd9fd35-37d1-49d3-a84f-368998c608d4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9190657398259657"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E00vx5rgXX07",
        "outputId": "10f501a6-4c57-489b-f6bc-2e492db553a1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37554966410001117"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame({'test_f1' :round( test_f1, 4),\n",
        "              'test_pearson' : round(test_pearson, 4),\n",
        "              'test_loss' : round(loss,4)},  index = ['value'])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "-4W6pOsHXZ1N",
        "outputId": "277b76a3-fda9-423a-93fa-7dae8b737b88"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       test_f1  test_pearson  test_loss\n",
              "value   0.8508        0.9191     0.3755"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b7c6ce2-11ea-45da-8e10-17b66f151be5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_pearson</th>\n",
              "      <th>test_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>0.8508</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>0.3755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b7c6ce2-11ea-45da-8e10-17b66f151be5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b7c6ce2-11ea-45da-8e10-17b66f151be5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b7c6ce2-11ea-45da-8e10-17b66f151be5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score\n",
        "pred_real_label = [pred[0] for pred in preds]\n",
        "pred_bi_label = [1 if i >= 3 else 0 for i in preds]\n",
        "\n",
        "\n",
        "dev_set_score = pd.DataFrame({'guid' : test['guid'],\n",
        "                              'true_real_label' : d_labels,\n",
        "                              'true_binary_label' : d_b_labels,\n",
        "                              'pred_real_label' : pred_real_label,\n",
        "                              'predict_binary_label' : pred_bi_label })\n",
        "dev_set_score.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "BEM-EYWdXg14",
        "outputId": "0d299a63-367f-462f-a923-de5528d82cc9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    guid  true_real_label  true_binary_label  pred_real_label  \\\n",
              "0  klue-sts-v1_dev_00000         4.857143                  1         4.947200   \n",
              "1  klue-sts-v1_dev_00001         1.428571                  0         2.495238   \n",
              "2  klue-sts-v1_dev_00002         1.285714                  0         1.144429   \n",
              "\n",
              "   predict_binary_label  \n",
              "0                     1  \n",
              "1                     0  \n",
              "2                     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4254a81d-02e1-49e0-a1ab-4931f5d454b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>true_real_label</th>\n",
              "      <th>true_binary_label</th>\n",
              "      <th>pred_real_label</th>\n",
              "      <th>predict_binary_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>klue-sts-v1_dev_00000</td>\n",
              "      <td>4.857143</td>\n",
              "      <td>1</td>\n",
              "      <td>4.947200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>klue-sts-v1_dev_00001</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0</td>\n",
              "      <td>2.495238</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>klue-sts-v1_dev_00002</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0</td>\n",
              "      <td>1.144429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4254a81d-02e1-49e0-a1ab-4931f5d454b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4254a81d-02e1-49e0-a1ab-4931f5d454b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4254a81d-02e1-49e0-a1ab-4931f5d454b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fname = 'koelectra_mine_dev_set_score.csv'\n",
        "dev_set_score.to_csv(fname)"
      ],
      "metadata": {
        "id": "Mx0537bnaVRM"
      },
      "execution_count": 92,
      "outputs": []
    }
  ]
}